{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from gsmmodem.modem import GsmModem\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "audio_format = pyaudio.paFloat32\n",
    "audio_rate = 44100\n",
    "audio_channels = 1\n",
    "audio_device_index = 1\n",
    "audio_frames_per_buffer = 4096\n",
    "audio_sample_duration = 3\n",
    "input_shape = (audio_rate, 1)\n",
    "modem_port = '/dev/ttyUSB0'\n",
    "modem_baudrate = 115200\n",
    "modem_sim_pin = None # SIM card PIN (if any)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing a Connection to the SMS Modem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Initializing connection to modem...\")\n",
    "modem = GsmModem(modem_port, modem_baudrate)\n",
    "modem.smsTextMode = False\n",
    "modem.connect(modem_sim_pin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC (AUC) metric - Uses the import \"from tensorflow.keras import backend as K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Spectrogram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_shape = (128, 87, 1)\n",
    "learning_rate = 0.001\n",
    "optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "input_tensor = Input(shape=input_shape)\n",
    "filter_size = (3,3)\n",
    "maxpool_size = (3,3)\n",
    "activation = \"relu\"\n",
    "drop_out_rate = 0.1\n",
    "number_of_classes = 2\n",
    "metrics = [auc, \"accuracy\"]\n",
    "\n",
    "# Model Architecture\n",
    "x = layers.Conv2D(16, filter_size, activation=activation, padding=\"same\")(input_tensor)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPool2D(maxpool_size)(x)\n",
    "x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "x = layers.Conv2D(32, filter_size, activation=activation, padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPool2D(maxpool_size)(x)\n",
    "x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "x = layers.Conv2D(64, filter_size, activation=activation, padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPool2D(maxpool_size)(x)\n",
    "x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "x = layers.Conv2D(256, filter_size, activation=activation, padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.GlobalMaxPool2D()(x)\n",
    "x = layers.Dropout(rate=(drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "x = layers.Dense(64, activation=activation)(x)\n",
    "x = layers.Dense(1028, activation=activation)(x)\n",
    "output_tensor = layers.Dense(number_of_classes, activation=\"softmax\")(x)\n",
    "\n",
    "spec_model = tf.keras.Model(input_tensor, output_tensor)\n",
    "spec_model.compile(optimizer=optimizer, loss=keras.losses.binary_crossentropy, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Spectrogram Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spec_model.load_weights(\"./models/gunshot_sound_model_spectrograph_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_out_rate = 0.1\n",
    "learning_rate = 0.001\n",
    "number_of_epochs = 100\n",
    "number_of_classes = 2\n",
    "batch_size = 32\n",
    "optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "input_tensor = Input(shape=input_shape)\n",
    "metrics = [auc, \"accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = layers.Conv1D(16, 9, activation=\"relu\", padding=\"same\")(input_tensor)\n",
    "x = layers.Conv1D(16, 9, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool1D(16)(x)\n",
    "x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool1D(4)(x)\n",
    "x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool1D(4)(x)\n",
    "x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "x = layers.Conv1D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv1D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dropout(rate=(drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(1028, activation=\"relu\")(x)\n",
    "output_tensor = layers.Dense(number_of_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(input_tensor, output_tensor)\n",
    "model.compile(optimizer=optimizer, loss=keras.losses.binary_crossentropy, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Original Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"./models/gunshot_sound_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing and Processing Microphone Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pa = pyaudio.PyAudio()\n",
    "    \n",
    "stream = pa.open(format = audio_format,\n",
    "                 rate = audio_rate,\n",
    "                 channels = audio_channels,\n",
    "                 input_device_index = audio_device_index,\n",
    "                 frames_per_buffer = audio_frames_per_buffer,\n",
    "                 input = True)\n",
    "\n",
    "print(\"--- Recording Audio ---\")\n",
    "while(True):\n",
    "    np_array_data = []\n",
    "    \n",
    "    # Loops through the stream and appends audio chunks to the frame array\n",
    "    for i in range(0, int((audio_rate / audio_frames_per_buffer) * audio_sample_duration)):\n",
    "        data = stream.read(audio_frames_per_buffer, exception_on_overflow = False)\n",
    "        np_array_data.append(np.frombuffer(data, dtype=np.float32))\n",
    "    microphone_data = np.concatenate(np_array_data)\n",
    "    \n",
    "    # Allows discarding of quiet audio samples\n",
    "    print(max(microphone_data))\n",
    "    if max(microphone_data) >= 0.25:\n",
    "        # Performs post-processing on live audio samples\n",
    "        reformed_microphone_data = librosa.resample(y=microphone_data, orig_sr=audio_rate, target_sr=22050)\n",
    "        reformed_microphone_data = reformed_microphone_data[:audio_rate]\n",
    "        reformed_microphone_data = librosa.util.normalize(reformed_microphone_data)\n",
    "        reformed_microphone_data = reformed_microphone_data.reshape(-1, audio_rate, 1)\n",
    "        \n",
    "        # Passes a given audio sample into the model for prediction\n",
    "        probabilities = model.predict(reformed_microphone_data)\n",
    "        # probabilities = model.predict(np.zeros(shape=(1, audio_rate, 1)))\n",
    "        print(probabilities)\n",
    "        \n",
    "        # If the model detects a gunshot, an SMS alert will be sent to local authorities\n",
    "        try:\n",
    "            if (probabilities[0][1] >= 0.9):\n",
    "                message = \" (Testing) ALERT: A Gunshot Has Been Detected (Testing)\"\n",
    "                phone_numbers_to_message = [\"8163449956\", \"9176202840\", \"7857642331\"]\n",
    "                for number in phone_numbers_to_message:\n",
    "                    modem.sendSms(number, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the Audio Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def show(data):\n",
    "#     librosa.display.waveplot(data, sr=22050)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Saving Recorded Audio Sample (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.save(\"./recordings/reformed_microphone_data_pi.npy\", reformed_microphone_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Training Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training_sample, training_sample_rate = librosa.load(\"./training_samples/9229.wav\")\n",
    "# number_of_missing_hertz = 44100 - len(training_sample)\n",
    "# training_sample = np.array(training_sample.tolist() + [0 for i in range(number_of_missing_hertz)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Audio Samples to Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reformed_microphone_data = np.array(librosa.feature.melspectrogram(y=reformed_microphone_data.reshape(44100), sr=22050))\n",
    "# training_sample = np.array(librosa.feature.melspectrogram(y=training_sample, sr=22050))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_inference",
   "language": "python",
   "name": "model_inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
