{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "audio_format = pyaudio.paInt16\n",
    "audio_rate = 44100\n",
    "audio_channels = 1\n",
    "audio_device_index = 1\n",
    "audio_frames_per_buffer = 4096\n",
    "audio_sample_duration = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Microphone Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pa = pyaudio.PyAudio()\n",
    "    \n",
    "stream = pa.open(format = audio_format,\n",
    "                 rate = audio_rate,\n",
    "                 channels = audio_channels,\n",
    "                 input_device_index = audio_device_index,\n",
    "                 frames_per_buffer = audio_frames_per_buffer,\n",
    "                 input = True)\n",
    "\n",
    "print(\"Now recording audio...\")\n",
    "frames = []\n",
    "\n",
    "# loop through stream and append audio chunks to frame array\n",
    "for i in range(0, int((audio_rate / audio_frames_per_buffer) * audio_sample_duration)):\n",
    "    data = stream.read(audio_frames_per_buffer)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"Finished recording audio...\")\n",
    "\n",
    "# stop the stream, close it, and terminate the pyaudio instantiation\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "pa.terminate()\n",
    "\n",
    "# save the audio frames as .wav file\n",
    "wavefile = wave.open(\"test\",'wb')\n",
    "wavefile.setnchannels(audio_channels)\n",
    "wavefile.setsampwidth(pa.get_sample_size(audio_format))\n",
    "wavefile.setframerate(audio_rate)\n",
    "wavefile.writeframes(b''.join(frames))\n",
    "wavefile.close()\n",
    "\n",
    "# while True:\n",
    "#     try:\n",
    "#         block = stream.read(audio_input_frames_per_block)\n",
    "#         print(block)\n",
    "#     except:\n",
    "#         print(\"--- Error Trying to Process Microphone Audio ---\")\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_inference",
   "language": "python",
   "name": "model_inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
