{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to record X mins of audio, overlay gunshot clips on top of it, run inference on it with both the 1D and 2D\n",
    "#tflite models, and output precision, recall, etc, in order to evaluate the performance of models\n",
    "    #can easily jump to overlaying clips/inference if you already have a recording (jump down to \"Run models on\n",
    "    #overlaid audio\" section)\n",
    "    \n",
    "# https://stackoverflow.com/questions/54006031/tf-lite-model-test-fails-with-run-time-error\n",
    "\n",
    "    \n",
    "import pyaudio\n",
    "import librosa\n",
    "import wave\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "from array import array\n",
    "from scipy.io import wavfile\n",
    "import soundfile as sf\n",
    "import scipy.signal\n",
    "from queue import Queue\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import six\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables\n",
    "audio_format = pyaudio.paInt16\n",
    "audio_rate = 44100\n",
    "audio_channels = 1\n",
    "audio_device_index = 2\n",
    "audio_frames_per_buffer = 4410\n",
    "audio_sample_duration = 2\n",
    "sound_data = np.zeros(0, dtype = \"int16\")\n",
    "sound_normalization_threshold = 10 ** (-1.0 / 20)\n",
    "max_audio_frame_int_value = 2 ** 15 - 1\n",
    "confidence_level = 0.90\n",
    "\n",
    "#how long to record audio for (in minutes)\n",
    "recording_length = 30\n",
    "\n",
    "#booleans for which model to use\n",
    "USING_2D_RAW_SPECTROGRAM_MODEL = True\n",
    "USING_1D_TIME_SERIES_MODEL = False\n",
    "\n",
    "#directory to save files to\n",
    "#for my laptop\n",
    "files_directory = \"/Users/laurenogden/Downloads/\"\n",
    "#relative path to directory on github\n",
    "#files_directory = \"../recordings/\"\n",
    "\n",
    "#directory of gunshot files to put on top of data (2s or less long files)\n",
    "gunshot_directory = files_directory + \"Original Gunshot Trimmed/\"\n",
    "\n",
    "audio_analysis_queue = Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization function\n",
    "def normalize(sound_data):\n",
    "    \n",
    "    absolute_maximum_sound_datum = max(abs(i) for i in sound_data)\n",
    "    # Prevents a divide by zero scenario\n",
    "    if absolute_maximum_sound_datum == 0.0:\n",
    "        absolute_maximum_sound_datum = 0.001\n",
    "        \n",
    "    normalization_factor = float(sound_normalization_threshold * max_audio_frame_int_value) / absolute_maximum_sound_datum\n",
    "    \n",
    "    # Averages the volume out\n",
    "    r = array('h')\n",
    "    for datum in sound_data:\n",
    "        r.append(int(datum * normalization_factor))\n",
    "    return np.array(r, dtype = np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to save a wav file\n",
    "def create_wav_file(microphone_data, name):\n",
    "    librosa.output.write_wav(files_directory + name + \".wav\", microphone_data, 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints the times of each sound (mins : secs)\n",
    "def time_in_mins(index):\n",
    "    secs = index/22050\n",
    "    return str(int(secs//60)) + \":\" + str(secs%60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes a spectrogram for 2D CNN ~~ OLD\n",
    "def convert_to_spectrogram(data, sample_rate):\n",
    "    return np.array(librosa.feature.melspectrogram(y = data, sr = sample_rate), dtype = \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to make a spectrogram image for other 2D CNN ~~ OLD\n",
    "def power_to_db(S, ref = 1.0, amin = 1e-10, top_db = 80.0):\n",
    "    S = np.asarray(S)\n",
    "    if amin <= 0:\n",
    "        print('ParameterError: amin must be strictly positive')\n",
    "    if np.issubdtype(S.dtype, np.complexfloating):\n",
    "        print('Warning: power_to_db was called on complex input so phase '\n",
    "                      'information will be discarded. To suppress this warning, '\n",
    "                      'call power_to_db(np.abs(D)**2) instead.')\n",
    "        magnitude = np.abs(S)\n",
    "    else:\n",
    "        magnitude = S\n",
    "    if six.callable(ref):\n",
    "        # User supplied a function to calculate reference power\n",
    "        ref_value = ref(magnitude)\n",
    "    else:\n",
    "        ref_value = np.abs(ref)\n",
    "    log_spec = 10.0 * np.log10(np.maximum(amin, magnitude))\n",
    "    log_spec -= 10.0 * np.log10(np.maximum(amin, ref_value))\n",
    "    if top_db is not None:\n",
    "        if top_db < 0:\n",
    "            print('ParameterError: top_db must be non-negative')\n",
    "        log_spec = np.maximum(log_spec, log_spec.max() - top_db)\n",
    "    return log_spec\n",
    "\n",
    "\n",
    "def convert_spectrogram_to_image(spectrogram):\n",
    "    plt.interactive(False)\n",
    "    \n",
    "    figure = plt.figure(figsize = [0.72, 0.72], dpi = 400)\n",
    "    plt.tight_layout(pad = 0)\n",
    "    ax = figure.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    \n",
    "    librosa.display.specshow(power_to_db(spectrogram, ref = np.max))\n",
    "    \n",
    "    canvas = FigureCanvas(figure)\n",
    "    canvas.draw()\n",
    "    s, (width, height) = canvas.print_to_buffer()\n",
    "\n",
    "    image = np.fromstring(figure.canvas.tostring_rgb(), dtype = \"uint8\")\n",
    "    image = image.reshape((width, height, 3))\n",
    "    image = cv2.resize(image, (192, 192))\n",
    "\n",
    "    # Cleaning up the matplotlib instance\n",
    "    plt.close()    \n",
    "    figure.clf()\n",
    "    plt.close(figure)\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "    # Returns a NumPy array containing an image of a spectrogram\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to make a spectrogram ~~ NEW\n",
    "\n",
    "SAMPLE_RATE_PER_SECOND = 22050\n",
    "SAMPLE_RATE_PER_TWO_SECONDS = 44100\n",
    "HOP_LENGTH = 345 * 2\n",
    "MINIMUM_FREQUENCY = 20\n",
    "MAXIMUM_FREQUENCY = SAMPLE_RATE_PER_SECOND\n",
    "NUMBER_OF_MELS = 128\n",
    "NUMBER_OF_FFTS = NUMBER_OF_MELS * 20\n",
    "\n",
    "def convert_audio_to_spectrogram(data):\n",
    "    spectrogram = librosa.feature.melspectrogram(y=data, sr=SAMPLE_RATE_PER_TWO_SECONDS,\n",
    "                                                 hop_length=HOP_LENGTH,\n",
    "                                                 fmin=MINIMUM_FREQUENCY,\n",
    "                                                 fmax=MAXIMUM_FREQUENCY,\n",
    "                                                 n_mels=NUMBER_OF_MELS,\n",
    "                                                 n_fft=NUMBER_OF_FFTS)\n",
    "    spectrogram = power_to_db(spectrogram)\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    return spectrogram\n",
    "\n",
    "\n",
    "def power_to_db(S, ref=1.0, amin=1e-10, top_db=80.0):\n",
    "    S = np.asarray(S)\n",
    "    if amin <= 0:\n",
    "        logger.debug(\"ParameterError: amin must be strictly positive\")\n",
    "    if np.issubdtype(S.dtype, np.complexfloating):\n",
    "        logger.debug(\"Warning: power_to_db was called on complex input so phase information will be discarded.\")\n",
    "        magnitude = np.abs(S)\n",
    "    else:\n",
    "        magnitude = S\n",
    "    if six.callable(ref):\n",
    "        # User supplied a function to calculate reference power\n",
    "        ref_value = ref(magnitude)\n",
    "    else:\n",
    "        ref_value = np.abs(ref)\n",
    "    log_spec = 10.0 * np.log10(np.maximum(amin, magnitude))\n",
    "    log_spec -= 10.0 * np.log10(np.maximum(amin, ref_value))\n",
    "    if top_db is not None:\n",
    "        if top_db < 0:\n",
    "            logger.debug(\"ParameterError: top_db must be non-negative\")\n",
    "        log_spec = np.maximum(log_spec, log_spec.max() - top_db)\n",
    "    return log_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auc metric for loading original models\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback function for pyaudio strean\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    global sound_data\n",
    "    sound_buffer = np.frombuffer(in_data, dtype = \"int16\")\n",
    "    sound_data = np.append(sound_data, sound_buffer)\n",
    "    if len(sound_data) >= 88200:\n",
    "        audio_analysis_queue.put(sound_data)\n",
    "        #empty out sound_data\n",
    "        sound_data = np.zeros(0, dtype = \"int16\")\n",
    "\n",
    "    return (sound_buffer, pyaudio.paContinue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record X mins of audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open pyaudio stream\n",
    "pa = pyaudio.PyAudio()\n",
    "stream = pa.open(format = audio_format,\n",
    "                 rate = audio_rate,\n",
    "                 channels = audio_channels,\n",
    "                 input_device_index = audio_device_index,\n",
    "                 frames_per_buffer = audio_frames_per_buffer,\n",
    "                 input = True,\n",
    "                 stream_callback = callback)\n",
    "\n",
    "# Starts the callback thread\n",
    "stream.start_stream()\n",
    "\n",
    "#get first bit of mic data from the stream\n",
    "mic_data = audio_analysis_queue.get()\n",
    "mod_mic_data = librosa.resample(y = mic_data, orig_sr = audio_rate, target_sr = 22050)\n",
    "mod_mic_data = normalize(mod_mic_data)\n",
    "mic_data = mod_mic_data\n",
    "#create_wav_file(mod_mic_data, \"-1_\" + str(time.time()))\n",
    "\n",
    "#get 10 mins of audio data (300 2s clips)\n",
    "for i in range(0, recording_length*30 - 1):\n",
    "    #print(time.ctime(time.time()))\n",
    "    new_data = np.array(audio_analysis_queue.get(), dtype = \"int16\")\n",
    "    mod_new_data = librosa.resample(y = new_data, orig_sr = audio_rate, target_sr = 22050)\n",
    "    mod_mic_data = normalize(mod_new_data)\n",
    "    #create_wav_file(mod_new_data, str(i) + \"_\" + str(time.time()))\n",
    "    mic_data = np.append(mic_data, mod_new_data)\n",
    "\n",
    "#save the clip\n",
    "createwav_file(mic_data, str(recording_length) + \"_mins_background\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark loud noises in noise clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mark locations of loud noises in the clips (taps/claps/etc)\n",
    "\n",
    "#sort the data, figure out the threshold\n",
    "sorted_data = np.sort(mic_data)\n",
    "threshold = sorted_data[len(sorted_data) - int(len(sorted_data)*0.001)]\n",
    "\n",
    "#find all values above that threshold\n",
    "above_threshold = []\n",
    "for i in range(0, len(mic_data)):\n",
    "    if mic_data[i] > threshold:\n",
    "        above_threshold.append(i)\n",
    "\n",
    "#separate out individual sounds from that whole chunk\n",
    "distinct_sounds = []\n",
    "distinct_sounds.append(above_threshold[0])\n",
    "for i in range(1, len(above_threshold)):\n",
    "    #if within 5ms of each other, assume from same shot\n",
    "    if above_threshold[i] - above_threshold[i-1] > 0.05*22050:\n",
    "        distinct_sounds.append(above_threshold[i])\n",
    "\n",
    "#times relative to beginning of the saved clip\n",
    "print(\"There were \" + str(len(distinct_sounds)) + \" distinct loud sounds detected\")\n",
    "distinct_times = []\n",
    "for i in distinct_sounds:\n",
    "    distinct_times.append(i/22050)\n",
    "    \n",
    "#save them in a txt file for future possible use\n",
    "loud_noises_file = open(files_directory + \"background_loud_noises_indices.txt\", \"w\")\n",
    "for i in distinct_sounds:\n",
    "    loud_noises_file.write(str(i)+\"\\n\")\n",
    "loud_noises_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlay gunshot clips onto recorded noise clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load back the X min clip saved above (or whenever, idc)\n",
    "#10mins_lab is the 10 minutes I recorded on the Sizheng mic just sitting in the lab\n",
    "    #has some people talking, me tapping the mic, moving my water bottle, etc\n",
    "#noise, rate = librosa.load(files_directory + \"10mins_lab.wav\") \n",
    "#mohler_outside.wav is what I named the hour long audio clip Dr. Mohler recorded outside his house on the Sizheng\n",
    "    #I'm only reading in half an hour of it because the whole hour seems like a lot\n",
    "noise, rate = librosa.load(files_directory + \"mohler_outside.wav\", duration = 60*30) \n",
    "#noise, rate = librosa.load(files_directory + str(recording_length) + \"_mins_background.wav\")\n",
    "\n",
    "#list files in a gunshot audio directory\n",
    "gunshot_files = os.listdir(gunshot_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a numpy array the size of your clip, fill it with zeros\n",
    "all_gunshots = np.zeros(len(noise), dtype = \"float32\")\n",
    "\n",
    "#how many gunshot clips to put on top of your audio\n",
    "n_gunshot_files_to_use = 125\n",
    "\n",
    "locs = []\n",
    "locs_of_actual_shots = []\n",
    "files_used = []\n",
    "#add gunshots to that 0 numpy array\n",
    "for i in range(0, n_gunshot_files_to_use):\n",
    "    #pick a random gunshot file\n",
    "    file = gunshot_files[np.random.randint(0, len(gunshot_files))]\n",
    "    #avoid using the exact same gunshot twice, or attempting to load a non-wav file in the folder\n",
    "    while file in files_used or \".wav\" not in file:\n",
    "        file = gunshot_files[np.random.randint(0, len(gunshot_files))]\n",
    "    files_used.append(file)\n",
    "    #load the file\n",
    "    print(gunshot_directory + file)\n",
    "    gunshot, sr = librosa.load(gunshot_directory + file)\n",
    "    \n",
    "    \n",
    "    #find the location(s) of the actual gunshot(s) in that file\n",
    "    #sort the data, figure out the threshold\n",
    "    sorted_gunshot_data = np.sort(gunshot)\n",
    "    threshold = sorted_gunshot_data[len(sorted_gunshot_data) - int(len(sorted_gunshot_data)*0.001)]\n",
    "    #find all values above that threshold\n",
    "    above_threshold = []\n",
    "    for i in range(0, len(gunshot)):\n",
    "        if gunshot[i] > threshold:\n",
    "            above_threshold.append(i)\n",
    "    #separate out individual sounds from that whole chunk\n",
    "    distinct_shots = []\n",
    "    distinct_shots.append(above_threshold[0])\n",
    "    for i in range(1, len(above_threshold)):\n",
    "        #if within 5ms of each other, assume from same shot\n",
    "        if above_threshold[i] - above_threshold[i-1] > 0.05*22050:\n",
    "            distinct_shots.append(above_threshold[i])\n",
    "    \n",
    "    \n",
    "    #pick a random location to put it at \n",
    "    loc = np.random.randint(0, len(noise) - 44100)\n",
    "    #to avoid putting two gunshots at the exact same place in the clip\n",
    "        #to be improved potentially to avoid overlapping gunshots??\n",
    "    while loc in locs:\n",
    "        loc = np.random.randint(0, len(noise))\n",
    "    locs.append(loc)\n",
    "    #append location(s) of the actual gunshot(s) in the entire clip\n",
    "    for i in distinct_shots:\n",
    "        locs_of_actual_shots.append(loc+i)\n",
    "    \n",
    "    #print(\"putting \" + file + \" at location \" + str(loc) + \", time= \" + time_in_mins(loc))\n",
    "    \n",
    "    #place the data at that location\n",
    "    for j in range(loc, loc+len(gunshot)):\n",
    "        all_gunshots[j] = all_gunshots[j] + gunshot[j-loc]\n",
    "    \n",
    "#combine the noise clip with the gunshot array and save it\n",
    "overlaid = noise * 0.7 + all_gunshots * 1.2\n",
    "overlaid_normed = normalize(overlaid)\n",
    "create_wav_file(overlaid_normed, str(recording_length) + \"_mins_overlaid\")\n",
    "\n",
    "#save the audio of just the gunshots w silence in the back (no noise clip) to see how the model does on that as well\n",
    "create_wav_file(all_gunshots, str(recording_length) + \"_only_gunshots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save locations of gunshots in new overlaid clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the list of locations of actual gunshots\n",
    "print(\"Added \" + str(len(locs_of_actual_shots)) + \" gunshots\")\n",
    "locs_of_actual_shots.sort()\n",
    "'''\n",
    "print(\"Times of the gunshots in the recording: \")\n",
    "for i in locs_of_actual_shots:\n",
    "    print(\"location = \" + str(i) + \" at time = \" + str(time_in_mins(i)))\n",
    "'''\n",
    "    \n",
    "#figure out what two second clips contain gunshots\n",
    "clips_w_guns = []\n",
    "for i in range(0, len(noise), 44100):\n",
    "    for j in locs_of_actual_shots:\n",
    "        if j in range(i, i+44100):\n",
    "            if i not in clips_w_guns:\n",
    "                clips_w_guns.append(i)\n",
    "\n",
    "print(\"There are \" + str(len(clips_w_guns)) + \" 2s clips in our \" + str(len(noise)/22050/60) \n",
    "      + \" min recording containing gunshots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all of the clips with guns for evaluation purposes if you feel like it\n",
    "'''\n",
    "for i in clips_w_guns:\n",
    "    #print(time_in_mins(i))\n",
    "    create_wav_file(overlaid_normed[i: i+44100], \"contains_gunshot_\" + time_in_mins(i))\n",
    "'''\n",
    "    \n",
    "#save the indices of the clips with guns in a textfile for later use\n",
    "locations_file = open(files_directory + str(recording_length) + \"_gunshot_clip_indices.txt\", \"w\")\n",
    "for i in clips_w_guns:\n",
    "    locations_file.write(str(i)+\"\\n\")\n",
    "locations_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models on overlaid audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load back in the clip overlaid with gunshots\n",
    "#audio, sr = librosa.load(files_directory + \"10mins_overlaid.wav\")\n",
    "audio, sr = librosa.load(files_directory + str(recording_length) + \"_mins_overlaid.wav\")\n",
    "\n",
    "#or load back in the clip with only gunshots and silence\n",
    "#audio, sr = librosa.load(files_directory + str(recording_length) + \"_only_gunshots.wav\")\n",
    "\n",
    "#or load back in just the noise clip w no gunshots\n",
    "#audio, sr = librosa.load(files_directory + \"10mins_lab.wav\")\n",
    "#audio, sr = librosa.load(files_directory + str(recording_length) + \"_mins_background.wav\")\n",
    "\n",
    "#load back the indices of clips that contain gunshots from the txt file\n",
    "#locations_file = open(files_directory + \"gunshot_clip_indices.txt\", \"r\")\n",
    "locations_file = open(files_directory + str(recording_length) + \"_gunshot_clip_indices.txt\", \"r\")\n",
    "clips_w_guns = locations_file.readlines()\n",
    "locations_file.close()\n",
    "#turn strings to ints\n",
    "clips_w_guns = list(map(int, clips_w_guns))\n",
    "#print(clips_w_guns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 1D tflite model\n",
    "interpreter_1D = tf.lite.Interpreter(model_path=\"../models/gunshot_sound_model.tflite\")\n",
    "interpreter_1D.allocate_tensors()\n",
    "# Get input and output tensors.\n",
    "input_details_1D = interpreter_1D.get_input_details()\n",
    "output_details_1D = interpreter_1D.get_output_details()\n",
    "input_shape_1D = input_details_1D[0]['shape']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 2D tflite model\n",
    "#interpreter_2D = tf.lite.Interpreter(model_path=\"../models/spectro_no_variables.tflite\")\n",
    "interpreter_2D = tf.lite.Interpreter(model_path=\"../models/revised_converted_model.tflite\")\n",
    "interpreter_2D.allocate_tensors()\n",
    "# Get input and output tensors.\n",
    "input_details_2D = interpreter_2D.get_input_details()\n",
    "output_details_2D = interpreter_2D.get_output_details()\n",
    "input_shape_2D = input_details_2D[0]['shape']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D Image TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 2D tflite model\n",
    "interpreter_2D_image = tf.lite.Interpreter(model_path=\"../models/gunshot_2d_spectrogram_model.tflite\")\n",
    "interpreter_2D_image.allocate_tensors()\n",
    "# Get input and output tensors.\n",
    "input_details_2D_image = interpreter_2D_image.get_input_details()\n",
    "output_details_2D_image = interpreter_2D_image.get_output_details()\n",
    "input_shape_2D_image = input_details_2D_image[0]['shape']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ryan's 2D TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 2D tflite model\n",
    "interpreter_2D_ryan = tf.lite.Interpreter(model_path=\"../models/SAME_INDEX_gunshot_2d_spectrogram_model.tflite\")\n",
    "interpreter_2D_ryan.allocate_tensors()\n",
    "# Get input and output tensors.\n",
    "input_details_2D_ryan = interpreter_2D_ryan.get_input_details()\n",
    "output_details_2D_ryan = interpreter_2D_ryan.get_output_details()\n",
    "input_shape_2D_ryan = input_details_2D_ryan[0]['shape']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open a file to save metrics and other information about the audio clip, etc\n",
    "metrics_file = open(files_directory + \"model_metrics.txt\", \"w\")\n",
    "metrics_file.write(\"There are \" + str(recording_length*30) + \" 2 second clips, \" \n",
    "                           + str(len(clips_w_guns)) + \" of which contain gunshots.\\n\")\n",
    "metrics_file.write(\"Predictions were done at a confidence level of \" + str(confidence_level) + \"\\n\\n\")\n",
    "metrics_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_1D = []\n",
    "positives_2D = []\n",
    "positives_2D_image = []\n",
    "positives_2D_ryan = []\n",
    "\n",
    "#pass two second slices into each of the models to predict\n",
    "for i in range (0, len(audio), 44100):\n",
    "    audio_slice = audio[i:i+44100]\n",
    "    \n",
    "    #Normalize\n",
    "    audio_slice = normalize(audio_slice)\n",
    "\n",
    "    #1D reshaping\n",
    "    reshaped_audio_slice_1D = audio_slice.reshape(input_shape_1D)\n",
    "    #1D predictions\n",
    "    input_tensor_1D = tf.convert_to_tensor(reshaped_audio_slice_1D, np.float32)\n",
    "    interpreter_1D.set_tensor(input_details_1D[0][\"index\"], reshaped_audio_slice_1D.astype(\"float32\"))\n",
    "    interpreter_1D.invoke()\n",
    "    probabilities_1D = interpreter_1D.get_tensor(output_details_1D[0][\"index\"])\n",
    "    if probabilities_1D[0][1] >= confidence_level:\n",
    "        #create_wav_file(audio_slice, str(i))\n",
    "        positives_1D.append(i)    \n",
    "        \n",
    "        \n",
    "    #2D reshaping\n",
    "    reshaped_audio_slice_2D = convert_audio_to_spectrogram(data = audio_slice)\n",
    "    reshaped_audio_slice_2D = reshaped_audio_slice_2D.reshape(input_shape_2D)\n",
    "    #2D predictions\n",
    "    input_tensor_2D = tf.convert_to_tensor(reshaped_audio_slice_2D, np.float32)\n",
    "    interpreter_2D.set_tensor(input_details_2D[0][\"index\"], reshaped_audio_slice_2D)\n",
    "    interpreter_2D.invoke()\n",
    "    probabilities_2D = interpreter_2D.get_tensor(output_details_2D[0][\"index\"])\n",
    "    if probabilities_2D[0][1] >= confidence_level:\n",
    "        #create_wav_file(audio_slice, str(i))\n",
    "        positives_2D.append(i) \n",
    "                \n",
    "        \n",
    "    #2D Image reshaping\n",
    "    reshaped_audio_slice_2D_image = convert_audio_to_spectrogram(data = audio_slice)\n",
    "    reshaped_audio_slice_2D_image = reshaped_audio_slice_2D_image.reshape(input_shape_2D_image)\n",
    "    reshaped_audio_slice_2D_image = reshaped_audio_slice_2D_image.astype(\"float32\")\n",
    "    #reshaped_audio_slice_2D_image /= 255\n",
    "    #2D Image predictions\n",
    "    input_tensor_2D_image = tf.convert_to_tensor(reshaped_audio_slice_2D_image, np.float32)\n",
    "    interpreter_2D_image.set_tensor(input_details_2D_image[0][\"index\"], reshaped_audio_slice_2D_image)\n",
    "    interpreter_2D_image.invoke()\n",
    "    probabilities_2D_image = interpreter_2D_image.get_tensor(output_details_2D_image[0][\"index\"])\n",
    "    if probabilities_2D_image[0][1] >= confidence_level:\n",
    "        #create_wav_file(audio_slice, str(i))\n",
    "        positives_2D_image.append(i) \n",
    "    \n",
    "    \n",
    "    #Ryan 2D reshaping\n",
    "    reshaped_audio_slice_2D_ryan = convert_audio_to_spectrogram(data = audio_slice)\n",
    "    #reshaped_audio_slice_2D_ryan = convert_spectrogram_to_ryan(spectrogram = reshaped_audio_slice_2D_ryan)\n",
    "    reshaped_audio_slice_2D_ryan = reshaped_audio_slice_2D_ryan.reshape(input_shape_2D_ryan)\n",
    "    reshaped_audio_slice_2D_ryan = reshaped_audio_slice_2D_ryan.astype(\"float32\")\n",
    "    #reshaped_audio_slice_2D_ryan /= 255\n",
    "    #Ryan 2D Image predictions\n",
    "    input_tensor_2D_ryan = tf.convert_to_tensor(reshaped_audio_slice_2D_ryan, np.float32)\n",
    "    interpreter_2D_ryan.set_tensor(input_details_2D_ryan[0][\"index\"], reshaped_audio_slice_2D_ryan)\n",
    "    interpreter_2D_ryan.invoke()\n",
    "    probabilities_2D_ryan = interpreter_2D_ryan.get_tensor(output_details_2D_image[0][\"index\"])\n",
    "    if probabilities_2D_ryan[0][1] >= confidence_level:\n",
    "        #create_wav_file(audio_slice, str(i))\n",
    "        positives_2D_ryan.append(i) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate TP, FP, TN, FN and output metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find true positives\n",
    "def find_true_positives(positives, model_name):\n",
    "    true_positives = []\n",
    "    for i in positives:\n",
    "        if i in clips_w_guns:\n",
    "            true_positives.append(i)\n",
    "            #create_wav_file(audio[i: i+44100], model_name + \"_true_positive_\" + str(i))\n",
    "            #create_wav_file(normalize(audio[i: i+44100]), model_name + \"_true_positive_\" + str(i))\n",
    "            \n",
    "    print(len(true_positives))\n",
    "            \n",
    "    return true_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find false positives\n",
    "def find_false_positives(positives, true_positives, model_name):\n",
    "    false_positives = []\n",
    "    for i in positives:\n",
    "        if i not in true_positives:\n",
    "            false_positives.append(i)\n",
    "            #create_wav_file(audio[i: i+44100], model_name + \"_false_positive_\" + str(i))\n",
    "            #create_wav_file(normalize(audio[i: i+44100]), model_name + \"_false_positive_\" + str(i))\n",
    "            \n",
    "    return false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find false negatives\n",
    "def find_false_negatives(positives, model_name):\n",
    "    false_negatives = []\n",
    "    for i in clips_w_guns:\n",
    "        if i not in positives:\n",
    "            #slice_location = i//44100\n",
    "            false_negatives.append(i)\n",
    "            #create_wav_file(audio[i: i+44100], model_name + \"_false_negative_\" + str(i))\n",
    "            #create_wav_file(normalize(audio[i: i+44100]), model_name + \"_false_negative_\" + str(i))\n",
    "            \n",
    "    return false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate metrics (precison, recall, accuracy, etc)\n",
    "def find_metrics(positives, true_positives, false_positives, false_negatives, model_name):\n",
    "    total = recording_length*30\n",
    "    total_pos = len(positives)\n",
    "    total_neg = total - total_pos\n",
    "    TP = len(true_positives)\n",
    "    FP = len(false_positives)\n",
    "    FN = len(false_negatives)\n",
    "    TN = total_neg - FN \n",
    "\n",
    "    print(\"1D TFLite Model Metrics:\")\n",
    "    print(\"Total # of clips classified as gunshots: \" + str(total_pos))\n",
    "    print(\"True Positives: \" + str(TP))\n",
    "    print(\"False Positives: \" + str(FP))\n",
    "    print(\"False Negatives: \" + str(FN))\n",
    "    print(\"True Negatives: \" + str(TN))\n",
    "\n",
    "    #calculate precision, accuracy, recall, avoid dividing by 0\n",
    "    if TP + FP == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = TP / (TP + FP)\n",
    "    if TP + FN == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = TP / (TP + FN)\n",
    "    accuracy = (TP + TN) / total\n",
    "    print(\"Precision: \" + str(precision))\n",
    "    print(\"Recall: \" + str(recall))\n",
    "    print(\"Accuracy: \" + str(accuracy))\n",
    "    \n",
    "    #write metrics out to a text file\n",
    "    metrics_file = open(files_directory + \"model_metrics.txt\", \"a\")\n",
    "    metrics_file.write( model_name + \" Model Metrics: \\n\")\n",
    "    metrics_file.write(\"Total # of clips classified as gunshots: \" + str(total_pos) + \"\\n\")\n",
    "    metrics_file.write(\"True Positives: \" + str(TP) + \"\\n\")\n",
    "    metrics_file.write(\"False Positives: \" + str(FP) + \"\\n\")\n",
    "    metrics_file.write(\"False Negatives: \" + str(FN) + \"\\n\")\n",
    "    metrics_file.write(\"True Negatives: \" + str(TN) + \"\\n\")\n",
    "    metrics_file.write(\"Precision: \" + str(precision) + \"\\n\")\n",
    "    metrics_file.write(\"Recall: \" + str(recall) + \"\\n\")\n",
    "    metrics_file.write(\"Accuracy: \" + str(accuracy) + \"\\n\\n\")\n",
    "    metrics_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives_1D = []\n",
    "true_positives_1D = []\n",
    "false_negatives_1D = []\n",
    "\n",
    "#figure out all true positives\n",
    "true_positives_1D = find_true_positives(positives_1D, \"1D\")\n",
    "#figure out all false positives\n",
    "false_positives_1D = find_false_positives(positives_1D, true_positives_1D, \"1D\") \n",
    "#figure out all false negatives\n",
    "false_negatives_1D = find_false_negatives(positives_1D, \"1D\")\n",
    "\n",
    "find_metrics(positives_1D, true_positives_1D, false_positives_1D, false_negatives_1D, \"1D\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives_2D = []\n",
    "true_positives_2D = []\n",
    "false_negatives_2D = []\n",
    "\n",
    "#figure out all true positives\n",
    "true_positives_2D = find_true_positives(positives_2D, \"2D\")\n",
    "#figure out all false positives\n",
    "false_positives_2D = find_false_positives(positives_2D, true_positives_2D, \"2D\") \n",
    "#figure out all false negatives\n",
    "false_negatives_2D = find_false_negatives(positives_2D, \"2D\")\n",
    "\n",
    "find_metrics(positives_2D, true_positives_2D, false_positives_2D, false_negatives_2D, \"2D\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D Image TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives_2D_image = []\n",
    "true_positives_2D_image = []\n",
    "false_negatives_2D_image = []\n",
    "\n",
    "#figure out all true positives\n",
    "true_positives_2D_image = find_true_positives(positives_2D_image, \"2D_image\")\n",
    "#figure out all false positives\n",
    "false_positives_2D_image = find_false_positives(positives_2D_image, true_positives_2D_image, \"2D_image\") \n",
    "#figure out all false negatives\n",
    "false_negatives_2D_image = find_false_negatives(positives_2D_image, \"2D_image\")\n",
    "\n",
    "find_metrics(positives_2D_image, true_positives_2D_image, false_positives_2D_image, false_negatives_2D_image, \"2D_image\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ryan's 2D TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives_2D_ryan = []\n",
    "true_positives_2D_ryan = []\n",
    "false_negatives_2D_ryan = []\n",
    "\n",
    "#figure out all true positives\n",
    "true_positives_2D_ryan = find_true_positives(positives_2D_ryan, \"2D_ryan\")\n",
    "#figure out all false positives\n",
    "false_positives_2D_ryan = find_false_positives(positives_2D_ryan, true_positives_2D_ryan, \"2D_ryan\") \n",
    "#figure out all false negatives\n",
    "false_negatives_2D_ryan = find_false_negatives(positives_2D_ryan, \"2D_ryan\")\n",
    "\n",
    "find_metrics(positives_2D_ryan, true_positives_2D_ryan, false_positives_2D_ryan, false_negatives_2D_ryan, \"2D_ryan\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#find gunshot clips that all models classified correctly (TP for all models)\n",
    "all_classified_TPs = []\n",
    "for i in clips_w_guns:\n",
    "    if i in true_positives_1D and i in true_positives_2D and i in true_positives_2D_image and i in true_positives_1D_original:\n",
    "        all_classified_TPs.append(i)\n",
    "        \n",
    "print(\"There were \" + str(len(all_classified_TPs)) + \" gunshot clips that all models classified correctly:\")\n",
    "print(all_classified_TPs)\n",
    "        \n",
    "#find gunshot clips that all models classified incorrectly (FN for all models)\n",
    "all_classified_FNs = []\n",
    "for i in clips_w_guns:\n",
    "    if i in false_negatives_1D and i in false_negatives_2D and i in false_negatives_2D_image and i in false_negatives_1D_original:\n",
    "        all_classified_FNs.append(i)\n",
    "        \n",
    "print(\"There were \" + str(len(all_classified_FNs)) + \" gunshot clips that all models classified incorrectly:\")\n",
    "print(all_classified_FNs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
