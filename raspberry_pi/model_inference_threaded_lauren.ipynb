{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiprocess inference: currently, there is one analyze process running throughohut the duration of the program\n",
    "    #main adds the microphone_data to a queue which analyze gets from the queue and analyzes\n",
    "\n",
    "import pyaudio\n",
    "import librosa\n",
    "import logging\n",
    "import multiprocessing\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from multiprocessing import Process, active_children\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "#from gsmmodem.modem import GsmModem\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_format = pyaudio.paFloat32\n",
    "audio_rate = 44100\n",
    "audio_channels = 1\n",
    "audio_device_index = 0\n",
    "audio_frames_per_buffer = 4410\n",
    "audio_sample_duration = 2\n",
    "input_shape = (audio_rate, 1)\n",
    "modem_port = '/dev/ttyUSB0'\n",
    "modem_baudrate = 115200\n",
    "modem_sim_pin = None # SIM card PIN (if any)\n",
    "phone_numbers_to_message = [\"8163449956\", \"9176202840\", \"7857642331\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stream_handler = logging.StreamHandler(sys.stdout)\n",
    "logger = logging.getLogger('debugger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.FileHandler('spam.log')\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "emit_string = \"send message here\"\n",
    "logger.debug(emit_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing a Connection to the SMS Modem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Initializing connection to modem...\")\n",
    "#modem = GsmModem(modem_port, modem_baudrate)\n",
    "#modem.smsTextMode = False\n",
    "#modem.connect(modem_sim_pin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Thread Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_microphone_data(audio_rate, phone_numbers_to_message):\n",
    "    #removed modem, model, microphone_data from parameters\n",
    "\n",
    "    #LOAD THE MODEL\n",
    "    def auc(y_true, y_pred):\n",
    "        auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        return auc\n",
    "\n",
    "    drop_out_rate = 0.1\n",
    "    learning_rate = 0.001\n",
    "    number_of_epochs = 100\n",
    "    number_of_classes = 2\n",
    "    batch_size = 32\n",
    "    optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    metrics = [auc, \"accuracy\"]\n",
    "    \n",
    "    x = layers.Conv1D(16, 9, activation=\"relu\", padding=\"same\")(input_tensor)\n",
    "    x = layers.Conv1D(16, 9, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool1D(16)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv1D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.GlobalMaxPool1D()(x)\n",
    "    x = layers.Dropout(rate=(drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dense(1028, activation=\"relu\")(x)\n",
    "    output_tensor = layers.Dense(number_of_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = tf.keras.Model(input_tensor, output_tensor)\n",
    "    model.compile(optimizer=optimizer, loss=keras.losses.binary_crossentropy, metrics=metrics)\n",
    "    \n",
    "    model.load_weights(\"/Users/gabe/Desktop/gunshot_detection/raspberry_pi/models/gunshot_sound_model.h5\")\n",
    "\n",
    "    #infinite loop\n",
    "    while True:\n",
    "        \n",
    "        #will wait until something is in the queue to continue\n",
    "        microphone_data = q.get()\n",
    "        \n",
    "        # Performs post-processing on live audio samples\n",
    "        reformed_microphone_data = librosa.resample(y=microphone_data, orig_sr=audio_rate, target_sr=22050)\n",
    "        reformed_microphone_data = librosa.util.normalize(reformed_microphone_data)\n",
    "        reformed_microphone_data = reformed_microphone_data[:audio_rate]\n",
    "        reformed_microphone_data = reformed_microphone_data.reshape(-1, audio_rate, 1)\n",
    "\n",
    "        # Passes a given audio sample into the model for prediction\n",
    "        probabilities = model.predict(reformed_microphone_data)\n",
    "        emit_string = \"Probabilities derived by the model: \" + str(probabilities)\n",
    "        logger.debug(emit_string)\n",
    "\n",
    "        #send a text if gunshot if detected\n",
    "        if (probabilities[0][1] >= 0.9):\n",
    "            sms_alert_process = Process(target = send_sms_alert, args = (probabilities))\n",
    "            sms_alert_process.start()\n",
    "\n",
    "\n",
    "def send_sms_alert(probabilities):\n",
    "        # If the model detects a gunshot, an SMS alert will be sent to local authorities\n",
    "        logger.debug(\"~~~~~~~~pretend like I just sent a text message~~~~~~~~~~\")\n",
    "        '''\n",
    "        try:\n",
    "            modem.waitForNetworkCoverage(timeout=86400)\n",
    "            message = \" (Testing) ALERT: A Gunshot Has Been Detected (Testing)\"\n",
    "            for number in phone_numbers_to_message:\n",
    "                modem.sendSms(number, message)\n",
    "            stream_handler.emit(\" *** Sent out an SMS alert to all designated recipients *** \")\n",
    "        except:\n",
    "            stream_handler.emit(\"ERROR: Unable to successfully send an SMS alert to the designated recipients.\")\n",
    "            pass\n",
    "        finally:\n",
    "            stream_handler.emit(\" * Finished evaluating an audio sample with the model * \")\n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing Microphone Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the stream\n",
    "pa = pyaudio.PyAudio()\n",
    "    \n",
    "stream = pa.open(format = audio_format,\n",
    "                 rate = audio_rate,\n",
    "                 channels = audio_channels,\n",
    "                 input_device_index = audio_device_index,\n",
    "                 frames_per_buffer = audio_frames_per_buffer,\n",
    "                 input = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-5-d5828370393c>\", line 52, in analyze_microphone_data\n",
      "    microphone_data = q.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-46979ee597f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Loops through the stream and appends audio chunks to the frame array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_rate\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0maudio_frames_per_buffer\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maudio_sample_duration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_frames_per_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mnp_array_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmicrophone_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_array_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    q = multiprocessing.Queue()\n",
    "    analysis_process = Process(target = analyze_microphone_data, args = (audio_rate, phone_numbers_to_message))\n",
    "    analysis_process.start()\n",
    "\n",
    "    logger.debug(\"--- Recording Audio ---\")\n",
    "    while(True):\n",
    "        np_array_data = []\n",
    "\n",
    "        # Loops through the stream and appends audio chunks to the frame array\n",
    "        for i in range(0, int(audio_rate / audio_frames_per_buffer * audio_sample_duration)):\n",
    "            data = stream.read(audio_frames_per_buffer, exception_on_overflow = False)\n",
    "            np_array_data.append(np.frombuffer(data, dtype=np.float32))\n",
    "        microphone_data = np.concatenate(np_array_data)\n",
    "        emit_string = \"Cumulative length of a given two-second audio sample: \" + str(len(microphone_data))\n",
    "        logger.debug(emit_string)\n",
    "        emit_string = \"The maximum frequency value for a given two-second audio sample: \" + str(max(microphone_data))\n",
    "        logger.debug(emit_string)\n",
    "        \n",
    "\n",
    "\n",
    "        # If a sample meets a certain threshold, a new concurrent analysis process is created\n",
    "        if max(microphone_data) >= 0.001:\n",
    "            q.put(microphone_data)\n",
    "            \n",
    "\n",
    "        # Closes all finished processes    \n",
    "        kids = active_children()\n",
    "        #logger.debug(\"these are my active children: \")\n",
    "        #logger.debug(kids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
