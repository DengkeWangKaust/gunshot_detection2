{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import librosa\n",
    "import logging\n",
    "import time\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from gsmmodem.modem import GsmModem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('debugger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.FileHandler('spam.log')\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_format = pyaudio.paInt16\n",
    "audio_rate = 44100\n",
    "audio_channels = 1\n",
    "audio_device_index = 0\n",
    "audio_frames_per_buffer = 4410\n",
    "audio_sample_duration = 2\n",
    "phone_numbers_to_message = [\"8163449956\", \"9176202840\", \"7857642331\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Process Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiprocessing Inference: Currently, there is one audio analysis process running for the duration of the program\n",
    "# The main process adds the microphone data to the audio analysis queue which the audio analysis process then retrieves and analyzes\n",
    "# If the audio analysis process detects the sound of a gunshot, the audio analysis queue will add a \"1\" to the queue, signifying the detection of a gunshot\n",
    "\n",
    "def analyze_microphone_data(audio_rate):\n",
    "    \n",
    "    # ROC (AUC) metric - Uses the import \"from tensorflow.keras import backend as K\"\n",
    "    def auc(y_true, y_pred):\n",
    "        auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        return auc\n",
    "    \n",
    "    # 1D Time-Series Model Parameters\n",
    "    drop_out_rate = 0.1\n",
    "    learning_rate = 0.001\n",
    "    number_of_epochs = 100\n",
    "    number_of_classes = 2\n",
    "    batch_size = 32\n",
    "    optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "    input_shape = (audio_rate, 1)\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    metrics = [auc, \"accuracy\"]\n",
    "\n",
    "    # Loading 1D Time-Series Model\n",
    "    x = layers.Conv1D(16, 9, activation=\"relu\", padding=\"same\")(input_tensor)\n",
    "    x = layers.Conv1D(16, 9, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool1D(16)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv1D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.GlobalMaxPool1D()(x)\n",
    "    x = layers.Dropout(rate=(drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dense(1028, activation=\"relu\")(x)\n",
    "    output_tensor = layers.Dense(number_of_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = tf.keras.Model(input_tensor, output_tensor)\n",
    "    model.compile(optimizer=optimizer, loss=keras.losses.binary_crossentropy, metrics=metrics)\n",
    "    \n",
    "    # Loading 1D Time-Series Model Weights\n",
    "    model.load_weights(\"./models/gunshot_sound_model_normalized.h5\")\n",
    "    \n",
    "    # 2D Spectrogram Model Parameters\n",
    "#     input_shape = (128, 87, 1)\n",
    "#     input_tensor = Input(shape=input_shape)\n",
    "#     learning_rate = 0.001\n",
    "#     optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "#     filter_size = (3,3)\n",
    "#     maxpool_size = (3,3)\n",
    "#     activation = \"relu\"\n",
    "#     drop_out_rate = 0.1\n",
    "#     number_of_classes = 2\n",
    "#     metrics = [auc, \"accuracy\"]\n",
    "\n",
    "    # Loading 2D Spectrogram Model\n",
    "#     x = layers.Conv2D(16, filter_size, activation=activation, padding=\"same\")(input_tensor)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.MaxPool2D(maxpool_size)(x)\n",
    "#     x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "#     x = layers.Conv2D(32, filter_size, activation=activation, padding=\"same\")(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.MaxPool2D(maxpool_size)(x)\n",
    "#     x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "#     x = layers.Conv2D(64, filter_size, activation=activation, padding=\"same\")(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.MaxPool2D(maxpool_size)(x)\n",
    "#     x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "#     x = layers.Conv2D(256, filter_size, activation=activation, padding=\"same\")(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.GlobalMaxPool2D()(x)\n",
    "#     x = layers.Dropout(rate=(drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "#     x = layers.Dense(64, activation=activation)(x)\n",
    "#     x = layers.Dense(1028, activation=activation)(x)\n",
    "#     output_tensor = layers.Dense(number_of_classes, activation=\"softmax\")(x)\n",
    "\n",
    "#     spec_model = tf.keras.Model(input_tensor, output_tensor)\n",
    "#     spec_model.compile(optimizer=optimizer, loss=keras.losses.binary_crossentropy, metrics=metrics)\n",
    "\n",
    "    # Loading 2D Spectrogram Model Weights\n",
    "#     spec_model.load_weights(\"./models/gunshot_sound_model_spectrograph_model.h5\")\n",
    "    \n",
    "    # The audio analysis process will run indefinitely\n",
    "    while True:\n",
    "        \n",
    "        # Waits to continue until something is in the queue\n",
    "        analysis_lock.acquire()\n",
    "        microphone_data = audio_analysis_queue.get()\n",
    "        analysis_lock.release()\n",
    "        \n",
    "        # Performs post-processing on live audio samples\n",
    "        reformed_microphone_data = librosa.resample(y=microphone_data, orig_sr=audio_rate, target_sr=22050)\n",
    "        reformed_microphone_data = librosa.util.normalize(reformed_microphone_data)\n",
    "        reformed_microphone_data = reformed_microphone_data[:audio_rate]\n",
    "        reformed_microphone_data = reformed_microphone_data.reshape(-1, audio_rate, 1)\n",
    "\n",
    "        # Passes a given audio sample into the model for prediction\n",
    "        probabilities = model.predict(reformed_microphone_data)\n",
    "        logger_message = \"Probabilities derived by the model: \" + str(probabilities)\n",
    "        logger.debug(logger_message)\n",
    "        if (probabilities[0][1] >= 0.9):\n",
    "            sms_alert_queue.put(1)\n",
    "\n",
    "\n",
    "def send_sms_alert(phone_numbers_to_message):\n",
    "    \n",
    "    return 0\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuring the Modem Connection\n",
    "    modem_port = '/dev/ttyUSB0'\n",
    "    modem_baudrate = 115200\n",
    "    modem_sim_pin = None  # SIM card PIN (if any)\n",
    "    \n",
    "    # Establishing a Connection to the SMS Modem\n",
    "    logger.debug(\"Initializing connection to modem...\")\n",
    "    modem = GsmModem(modem_port, modem_baudrate)\n",
    "    modem.smsTextMode = False\n",
    "    modem.connect(modem_sim_pin)\n",
    "    \n",
    "    # The SMS alert process will run indefinitely\n",
    "    while True:\n",
    "        sms_alert_status = sms_alert_queue.get()\n",
    "        if sms_alert_status == 1:\n",
    "            try:\n",
    "                # At this point in execution, an attempt to send an SMS alert to local authorities will be made\n",
    "                modem.waitForNetworkCoverage(timeout=86400)\n",
    "                message = \" (Testing) ALERT: A Gunshot Has Been Detected (Testing)\"\n",
    "                for number in phone_numbers_to_message:\n",
    "                    modem.sendSms(number, message)\n",
    "                logger.debug(\" *** Sent out an SMS alert to all designated recipients *** \")\n",
    "            except:\n",
    "                logger.debug(\"ERROR: Unable to successfully send an SMS alert to the designated recipients.\")\n",
    "                pass\n",
    "            finally:\n",
    "                logger.debug(\" ** Finished evaluating an audio sample with the model ** \")\n",
    "    \n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening the Microphone Audio Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = pyaudio.PyAudio()\n",
    "    \n",
    "stream = pa.open(format = audio_format,\n",
    "                 rate = audio_rate,\n",
    "                 channels = audio_channels,\n",
    "                 input_device_index = audio_device_index,\n",
    "                 frames_per_buffer = audio_frames_per_buffer,\n",
    "                 input = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing Microphone Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.debug(\"--- Listening to Audio Stream ---\")\n",
    "\n",
    "analysis_lock = multiprocessing.Lock()\n",
    "analysis_lock.acquire()\n",
    "analysis_lock.release()\n",
    "logger.debug(\"med it\")\n",
    "\n",
    "audio_analysis_queue = multiprocessing.Queue()\n",
    "audio_analysis_process = multiprocessing.Process(target = analyze_microphone_data, args = (audio_rate,))\n",
    "audio_analysis_process.start()\n",
    "\n",
    "sms_alert_queue = multiprocessing.Queue()\n",
    "sms_alert_process = multiprocessing.Process(target = send_sms_alert, args = (phone_numbers_to_message,))\n",
    "sms_alert_process.start()\n",
    "\n",
    "while True:\n",
    "    sound_data = []\n",
    "    \n",
    "    # Loops through the stream and appends audio chunks to the frame array\n",
    "    for i in range(0, int(audio_rate / audio_frames_per_buffer * audio_sample_duration)):\n",
    "        sound_buffer = stream.read(audio_frames_per_buffer, exception_on_overflow = False)\n",
    "        sound_data.append(np.frombuffer(sound_buffer, dtype=np.float32))\n",
    "    microphone_data = np.concatenate(sound_data)\n",
    "    logger_message = \"Cumulative length of a given two-second audio sample: \" + str(len(microphone_data))\n",
    "    #logger.debug(logger_message)\n",
    "    logger_message = \"The maximum frequency value for a given two-second audio sample: \" + str(max(microphone_data))\n",
    "    #logger.debug(logger_message)\n",
    "    \n",
    "    # If a sample meets a certain threshold, a new batch of microphone data is placed on the queue\n",
    "    if max(microphone_data) >= 0.001:\n",
    "        analysis_lock.acquire()\n",
    "        logger.debug(\"lock\")\n",
    "        audio_analysis_queue.put(microphone_data)\n",
    "        analysis_lock.release()\n",
    "        \n",
    "    # Closes all finished processes   \n",
    "    children = multiprocessing.active_children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
