{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import librosa\n",
    "import logging\n",
    "import time\n",
    "import multiprocessing\n",
    "import audioop\n",
    "import wave\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from gsmmodem.modem import GsmModem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('debugger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.FileHandler('output.log')\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_format = pyaudio.paInt16\n",
    "audio_rate = 44100\n",
    "audio_channels = 1\n",
    "audio_device_index = 0\n",
    "audio_frames_per_buffer = 4410\n",
    "audio_sample_duration = 2\n",
    "audio_volume_threshold = 30000\n",
    "inference_model_confidence_threshold = 0.99\n",
    "designated_alert_recipients = [\"8163449956\", \"9176202840\", \"7857642331\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Augmented Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load(\"/home/alexm/Datasets/gunshot_augmented_sound_labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarizing Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = labels.astype(\"str\")\n",
    "labels = np.array([(\"gun_shot\" if label == \"1\" else \"other\") for label in labels])\n",
    "label_binarizer = LabelBinarizer()\n",
    "labels = label_binarizer.fit_transform(labels)\n",
    "labels = np.hstack((labels, 1 - labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sound Post-Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sound_data):\n",
    "    # Averages the volume out\n",
    "    sound_normalization_threshold = 16384\n",
    "    times = float(sound_normalization_threshold) / max(abs(i) for i in sound_data)\n",
    "    \n",
    "    r = array('h')\n",
    "    for datum in sound_data:\n",
    "        r.append(int(datum * times))\n",
    "    return np.array(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC (AUC) metric - Uses the import \"from tensorflow.keras import backend as K\"\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_one(weights_file):\n",
    "    # 1D Time-Series Model Parameters\n",
    "    drop_out_rate = 0.1\n",
    "    learning_rate = 0.001\n",
    "    number_of_epochs = 100\n",
    "    number_of_classes = 2\n",
    "    batch_size = 32\n",
    "    optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "    input_shape = (44100, 1)\n",
    "    input_tensor = Input(shape = input_shape)\n",
    "    metrics = [auc, \"accuracy\"]\n",
    "    \n",
    "    # Reconstructing 1D Time-Series Model\n",
    "    x = layers.Conv1D(16, 9, activation = \"relu\", padding = \"same\")(input_tensor)\n",
    "    x = layers.Conv1D(16, 9, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.MaxPool1D(16)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(256, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.Conv1D(256, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.GlobalMaxPool1D()(x)\n",
    "    x = layers.Dropout(rate = (drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "    x = layers.Dense(64, activation = \"relu\")(x)\n",
    "    x = layers.Dense(1028, activation = \"relu\")(x)\n",
    "    \n",
    "    # Compiling 1D Time-Series Model\n",
    "    output_tensor = layers.Dense(number_of_classes, activation = \"softmax\")(x)\n",
    "    model = tf.keras.Model(input_tensor, output_tensor)\n",
    "    model.compile(optimizer = optimizer, loss = keras.losses.binary_crossentropy, metrics = metrics)\n",
    "    \n",
    "    # Loading 1D Time-Series Model Weights\n",
    "    model.load_weights(weights_file)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_two(weights_file):\n",
    "    # 2D Spectrogram Model Parameters\n",
    "    input_shape = (128, 87, 1)\n",
    "    input_tensor = Input(shape = input_shape)\n",
    "    learning_rate = 0.001\n",
    "    optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "    filter_size = (3,3)\n",
    "    maxpool_size = (3,3)\n",
    "    activation = \"relu\"\n",
    "    drop_out_rate = 0.1\n",
    "    number_of_classes = 2\n",
    "    metrics = [auc, \"accuracy\"]\n",
    "    \n",
    "    # Reconstructing 2D Spectrogram Model\n",
    "    x = layers.Conv2D(16, filter_size, activation = activation, padding = \"same\")(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(32, filter_size, activation = activation, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, filter_size, activation = activation, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(256, filter_size, activation = activation, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalMaxPool2D()(x)\n",
    "    x = layers.Dropout(rate = (drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "    x = layers.Dense(64, activation = activation)(x)\n",
    "    x = layers.Dense(1028, activation = activation)(x)\n",
    "    \n",
    "    # Compiling 2D Spectrogram Model\n",
    "    output_tensor = layers.Dense(number_of_classes, activation = \"softmax\")(x)\n",
    "    spec_model = tf.keras.Model(input_tensor, output_tensor)\n",
    "    spec_model.compile(optimizer = optimizer, loss = keras.losses.binary_crossentropy, metrics = metrics)\n",
    "\n",
    "    # Loading 2D Spectrogram Model Weights\n",
    "    spec_model.load_weights(weights_file)\n",
    "    \n",
    "    return spec_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing Inference: A main process which adds two second samples of microphone data to the audio analysis queue; An audio analysis process which retrieves and analyzes samples in the audio analysis queue; A prediction process which detects the presence of a gunshot in an analyzed audio sample; And an SMS alert process which dispatches groups of messages to designated recipients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Multiprocess Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_microphone_data(audio_volume_threshold):\n",
    "    # Instantiates our sequence management variable\n",
    "    sequence_started = False\n",
    "    \n",
    "    # The audio analysis process will run indefinitely\n",
    "    while True:\n",
    "        # Gets a sample from the audio analysis queue\n",
    "        microphone_data = audio_analysis_queue.get()\n",
    "        maximum_frequency_value = max(microphone_data)\n",
    "        \n",
    "        # Outputs a given sample's maximum frequency value\n",
    "        logger.debug(\"The maximum frequency value for a given two-second audio sample: \" + str(maximum_frequency_value))\n",
    "        \n",
    "        # If a sample meets a certain threshold, it is placed on the gunshot sequence queue\n",
    "        if maximum_frequency_value >= audio_volume_threshold and not sequence_started:\n",
    "            sequence_started = True\n",
    "            gunshot_sequence_queue.put(microphone_data)\n",
    "            gunshot_sequence_queue.put(maximum_frequency_value)\n",
    "            \n",
    "        # Until there are four samples (plus one frequency value) in the gunshot sequence queue, we continue to fill the gunshot sequence queue\n",
    "        elif sequence_started and gunshot_sequence_queue.qsize() < 5:\n",
    "            gunshot_sequence_queue.put(microphone_data)\n",
    " \n",
    "        # Once there are four samples (plus one frequency value) in the gunshot sequence queue, we process them to make three new samples\n",
    "        elif gunshot_sequence_queue.qsize() == 5:\n",
    "            # Pops off four samples from the gunshot sequence queue\n",
    "            first_slice = gunshot_sequence_queue.get()\n",
    "            maximum_frequency_value = gunshot_sequence_queue.get()\n",
    "            second_slice = gunshot_sequence_queue.get()\n",
    "            third_slice = gunshot_sequence_queue.get()\n",
    "            fourth_slice = gunshot_sequence_queue.get()\n",
    "            \n",
    "            # Finds the location of the first maximum frequency value in the sequence\n",
    "            maximum_frequency_value_location = first_slice.index(maximum_frequency_value)\n",
    "            \n",
    "            # Creates three new samples from the four original samples with the start of the first sample being where the loud noise occurred\n",
    "            new_first_slice = first_slice[maximum_frequency_value_location:] + second_slice[:(88200 - maximum_frequency_value_location)]\n",
    "            new_second_slice = second_slice[maximum_frequency_value_location:] + third_slice[:(88200 - maximum_frequency_value_location)]\n",
    "            new_third_slice = third_slice[maximum_frequency_value_location:] + fourth_slice[:(88200 - maximum_frequency_value_location)]\n",
    "            \n",
    "            # Packages the three samples into a list for inference by the model\n",
    "            loud_noise_sequence = [new_first_slice, new_second_slice, new_third_slice]\n",
    "            \n",
    "            # Places the new list of processed samples on the prediction queue\n",
    "            prediction_queue.put(loud_noise_sequence)\n",
    "                \n",
    "            # Marks the end of the loud noise sequence\n",
    "            sequence_started = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_microphone_data_class(audio_rate):\n",
    "    # Loading 1D Time-Series Model\n",
    "    model = load_model_one(\"./models/gunshot_sound_model.h5\")\n",
    "    \n",
    "    # Loading 2D Spectrogram Model\n",
    "#     model = load_model_two(\"./models/gunshot_sound_model_spectrograph_model.h5\")\n",
    "    \n",
    "    # An iterator variable for counting the number of gunshot sounds detected\n",
    "    gunshot_sound_counter = 1\n",
    "    \n",
    "    # The prediction process will run indefinitely\n",
    "    while True:\n",
    "        \n",
    "        # Waits to continue until something is in the queue\n",
    "        microphone_data = prediction_queue.get()\n",
    "            \n",
    "        # Unwraps the first slice from a list of microphone samples and packs it as a NumPy array\n",
    "        first_microphone_data_slice = microphone_data[0]\n",
    "                            \n",
    "        # Performs post-processing on an audio sample\n",
    "        first_microphone_data_slice = np.array(first_microphone_data_slice)\n",
    "        modified_microphone_data = librosa.resample(y = first_microphone_data_slice, orig_sr = audio_rate, target_sr = 22050)\n",
    "        modified_microphone_data = normalize(first_microphone_data_slice)\n",
    "        modified_microphone_data = modified_microphone_data[:44100]\n",
    "        modified_microphone_data = modified_microphone_data.reshape(-1, 44100, 1)\n",
    "\n",
    "        # Passes a given audio sample into the model for prediction\n",
    "        probabilities = model.predict(modified_microphone_data)\n",
    "        logger.debug(\"Probabilities derived by the model: \" + str(probabilities))\n",
    "        logger.debug(\"Model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities[:, 0])[0])\n",
    "        \n",
    "        if (probabilities[0][1] >= inference_model_confidence_threshold):\n",
    "            \n",
    "            # Sends out an SMS alert\n",
    "            sms_alert_queue.put(\"Gunshot Detected\")\n",
    "            \n",
    "            # Instantiates a new clip\n",
    "            new_clip = []\n",
    "            \n",
    "            # Post-processes the rest of the audio samples in the list\n",
    "            for sample in microphone_data:\n",
    "                sample = np.array(sample)\n",
    "                sample = librosa.resample(y = sample, orig_sr = audio_rate, target_sr = 22050)\n",
    "                sample = normalize(sample)\n",
    "                sample = sample[:44100]\n",
    "                new_clip += sample.tolist()\n",
    "                logger.debug(\"Length of new clip: \" + str(len(new_clip)))\n",
    "                \n",
    "            # Saves the new six-second sample as a WAV file\n",
    "            wave_file = wave.open(\"./recordings/Gunshot Sound Sample #\" + str(gunshot_sound_counter) + \".wav\", \"wb\")\n",
    "            wave_file.setnchannels(audio_channels)\n",
    "            wave_file.setsampwidth(2)\n",
    "            wave_file.setframerate(22050)\n",
    "            wave_file.writeframes(array('h', new_clip))\n",
    "            wave_file.close()\n",
    "            \n",
    "            # Increments the counter for gunshot sound file names\n",
    "            gunshot_sound_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_sms_alert(designated_alert_recipients):\n",
    "    # Continuously dispatches SMS alerts to a list of designated recipients\n",
    "    while True:\n",
    "        sms_alert_status = sms_alert_queue.get()\n",
    "        if sms_alert_status == \"Gunshot Detected\":\n",
    "            logger.debug(\"ALERT: A Gunshot Has Been Detected\")\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuring the Modem Connection\n",
    "    modem_port = '/dev/ttyUSB0'\n",
    "    modem_baudrate = 115200\n",
    "    modem_sim_pin = None  # SIM card PIN (if any)\n",
    "    \n",
    "    # Establishing a Connection to the SMS Modem\n",
    "    logger.debug(\"Initializing connection to modem...\")\n",
    "    modem = GsmModem(modem_port, modem_baudrate)\n",
    "    modem.smsTextMode = False\n",
    "    modem.connect(modem_sim_pin)\n",
    "    \n",
    "    # The SMS alert process will run indefinitely\n",
    "    while True:\n",
    "        sms_alert_status = sms_alert_queue.get()\n",
    "        if sms_alert_status == \"Gunshot Detected\":\n",
    "            try:\n",
    "                # At this point in execution, an attempt to send an SMS alert to local authorities will be made\n",
    "                modem.waitForNetworkCoverage(timeout = 86400)\n",
    "                message = \"(Testing) ALERT: A Gunshot Has Been Detected (Testing)\"\n",
    "                for number in designated_alert_recipients:\n",
    "                    modem.sendSms(number, message)\n",
    "                logger.debug(\" *** Sent out an SMS alert to all designated recipients *** \")\n",
    "            except:\n",
    "                logger.debug(\"ERROR: Unable to successfully send an SMS alert to the designated recipients.\")\n",
    "                pass\n",
    "            finally:\n",
    "                logger.debug(\" ** Finished evaluating an audio sample with the model ** \")\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening the Microphone Audio Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = pyaudio.PyAudio()\n",
    "    \n",
    "stream = pa.open(format = audio_format,\n",
    "                 rate = audio_rate,\n",
    "                 channels = audio_channels,\n",
    "                 input_device_index = audio_device_index,\n",
    "                 frames_per_buffer = audio_frames_per_buffer,\n",
    "                 input = True,\n",
    "                 output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing Microphone Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.debug(\"--- Listening to Audio Stream ---\")\n",
    "\n",
    "audio_analysis_process = multiprocessing.Process(target = analyze_microphone_data, args = (audio_volume_threshold,))\n",
    "prediction_process = multiprocessing.Process(target = predict_microphone_data_class, args = (audio_rate,))\n",
    "sms_alert_process = multiprocessing.Process(target = send_sms_alert, args = (designated_alert_recipients,))\n",
    "audio_analysis_queue = multiprocessing.Queue()\n",
    "gunshot_sequence_queue = multiprocessing.Queue()\n",
    "prediction_queue = multiprocessing.Queue()\n",
    "sms_alert_queue = multiprocessing.Queue()\n",
    "audio_analysis_process.start()\n",
    "prediction_process.start()\n",
    "sms_alert_process.start()\n",
    "\n",
    "while True:\n",
    "    sound_data = array('h')\n",
    "    \n",
    "    # Loops through the stream and appends audio chunks to the frame array\n",
    "    for i in range(0, int(audio_rate / audio_frames_per_buffer * audio_sample_duration)):\n",
    "        sound_buffer = array('h', stream.read(audio_frames_per_buffer, exception_on_overflow = False))\n",
    "        if byteorder == 'big':\n",
    "            sound_buffer.byteswap()\n",
    "        sound_data.extend(sound_buffer)\n",
    "    \n",
    "    # Places a new sample of microphone data on the audio analysis queue\n",
    "    audio_analysis_queue.put(sound_data)\n",
    "        \n",
    "    # Closes all finished processes   \n",
    "    multiprocessing.active_children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gunshot_detection",
   "language": "python",
   "name": "gunshot_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
