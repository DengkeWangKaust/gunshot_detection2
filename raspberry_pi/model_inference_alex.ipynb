{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import librosa\n",
    "import logging\n",
    "import time\n",
    "import multiprocessing\n",
    "import audioop\n",
    "import wave\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from gsmmodem.modem import GsmModem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('debugger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.FileHandler('output.log')\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_format = pyaudio.paInt16\n",
    "audio_rate = 44100\n",
    "audio_channels = 1\n",
    "audio_device_index = 5\n",
    "audio_frames_per_buffer = 4410\n",
    "audio_sample_duration = 2\n",
    "audio_volume_threshold = 100\n",
    "inference_model_confidence_threshold = 0.95\n",
    "max_audio_frame_int_value = 2 ** 15 - 1\n",
    "sound_normalization_threshold = 10 ** (-1.0 / 20)\n",
    "designated_alert_recipients = [\"8163449956\", \"9176202840\", \"7857642331\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Augmented Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load(\"/home/alexm/Datasets/gunshot_augmented_sound_labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarizing Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = np.array([(\"gun_shot\" if label == 1 else \"other\") for label in labels])\n",
    "label_binarizer = LabelBinarizer()\n",
    "labels = label_binarizer.fit_transform(labels)\n",
    "labels = np.hstack((labels, 1 - labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sound Post-Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sound_data):\n",
    "    normalization_factor = float(sound_normalization_threshold * max_audio_frame_int_value) / max(abs(i) for i in sound_data)\n",
    "    \n",
    "    # Averages the volume out\n",
    "    r = array('h')\n",
    "    for datum in sound_data:\n",
    "        r.append(int(datum * normalization_factor))\n",
    "    return np.array(r, dtype = np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC (AUC) metric - Uses the import \"from tensorflow.keras import backend as K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Time-Series Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_one(weights_file):\n",
    "    # Initializing 1D Time-Series Model Parameters\n",
    "    drop_out_rate = 0.1\n",
    "    learning_rate = 0.001\n",
    "    number_of_epochs = 100\n",
    "    number_of_classes = 2\n",
    "    batch_size = 32\n",
    "    optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "    input_shape = (44100, 1)\n",
    "    input_tensor = Input(shape = input_shape)\n",
    "    metrics = [auc, \"accuracy\"]\n",
    "    \n",
    "    # Reconstructing 1D Time-Series Model\n",
    "    x = layers.Conv1D(16, 9, activation = \"relu\", padding = \"same\")(input_tensor)\n",
    "    x = layers.Conv1D(16, 9, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.MaxPool1D(16)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(256, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.Conv1D(256, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.GlobalMaxPool1D()(x)\n",
    "    x = layers.Dropout(rate = (drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "    x = layers.Dense(64, activation = \"relu\")(x)\n",
    "    x = layers.Dense(1028, activation = \"relu\")(x)\n",
    "    \n",
    "    # Compiling 1D Time-Series Model\n",
    "    output_tensor = layers.Dense(number_of_classes, activation = \"softmax\")(x)\n",
    "    model = tf.keras.Model(input_tensor, output_tensor)\n",
    "    model.compile(optimizer = optimizer, loss = keras.losses.binary_crossentropy, metrics = metrics)\n",
    "    \n",
    "    # Loading 1D Time-Series Model Weights\n",
    "    model.load_weights(weights_file)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D Spectrogram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_two(weights_file):\n",
    "    # 2D Spectrogram Model Parameters\n",
    "    input_shape = (128, 87, 1)\n",
    "    input_tensor = Input(shape = input_shape)\n",
    "    learning_rate = 0.001\n",
    "    optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "    filter_size = (3,3)\n",
    "    maxpool_size = (3,3)\n",
    "    activation = \"relu\"\n",
    "    drop_out_rate = 0.1\n",
    "    number_of_classes = 2\n",
    "    metrics = [auc, \"accuracy\"]\n",
    "    \n",
    "    # Reconstructing 2D Spectrogram Model\n",
    "    x = layers.Conv2D(16, filter_size, activation = activation, padding = \"same\")(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(32, filter_size, activation = activation, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, filter_size, activation = activation, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(256, filter_size, activation = activation, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalMaxPool2D()(x)\n",
    "    x = layers.Dropout(rate = (drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "    x = layers.Dense(64, activation = activation)(x)\n",
    "    x = layers.Dense(1028, activation = activation)(x)\n",
    "    \n",
    "    # Compiling 2D Spectrogram Model\n",
    "    output_tensor = layers.Dense(number_of_classes, activation = \"softmax\")(x)\n",
    "    spec_model = tf.keras.Model(input_tensor, output_tensor)\n",
    "    spec_model.compile(optimizer = optimizer, loss = keras.losses.binary_crossentropy, metrics = metrics)\n",
    "\n",
    "    # Loading 2D Spectrogram Model Weights\n",
    "    spec_model.load_weights(weights_file)\n",
    "    \n",
    "    return spec_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing Inference: A main process which adds two second samples of microphone data to the audio analysis queue; An audio analysis process which detects the presence of gunshot sounds in samples retrieved from the audio analysis queue; And an SMS alert process which dispatches groups of messages to designated recipients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Multiprocess Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Analysis Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_microphone_data():\n",
    "    # Loading 1D Time-Series Model\n",
    "    model = load_model_one(\"./models/gunshot_sound_model.h5\")\n",
    "    \n",
    "    # Loading 2D Spectrogram Model\n",
    "#     model = load_model_two(\"./models/gunshot_sound_model_spectrograph_model.h5\")\n",
    "    \n",
    "    # An iterator variable for counting the number of gunshot sounds detected\n",
    "    gunshot_sound_counter = 1\n",
    "    \n",
    "    # The audio analysis process will run indefinitely\n",
    "    while True:\n",
    "        # Gets a sample and its timestamp from the audio analysis queue\n",
    "        microphone_data = np.array(audio_analysis_queue.get(), dtype = np.int16)\n",
    "        time_of_sample_occurrence = audio_analysis_queue.get()\n",
    "        \n",
    "        # Outputs the current sample's maximum frequency value\n",
    "        maximum_frequency_value = max(microphone_data)\n",
    "        logger.debug(\"The maximum frequency value of a given sample: \" + str(maximum_frequency_value))\n",
    "        \n",
    "        # Determines whether a given sample potentially contains a gunshot\n",
    "        if maximum_frequency_value >= audio_volume_threshold:\n",
    "        \n",
    "            # Post-processes the microphone data\n",
    "            modified_microphone_data = librosa.resample(y = microphone_data, orig_sr = audio_rate, target_sr = 22050)\n",
    "#             modified_microphone_data = normalize(modified_microphone_data)\n",
    "            modified_microphone_data = modified_microphone_data[:44100]\n",
    "            modified_microphone_data = modified_microphone_data.reshape(-1, 44100, 1)\n",
    "\n",
    "            # Passes a given audio sample into the model for prediction\n",
    "            probabilities = model.predict(modified_microphone_data)\n",
    "            logger.debug(\"The model-predicted probability values: \" + str(probabilities[0]))\n",
    "            logger.debug(\"Model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities[:, 0])[0])\n",
    "\n",
    "            # Determines if a gunshot sound was detected by the model\n",
    "            if (probabilities[0][1] >= inference_model_confidence_threshold):\n",
    "                # Sends out an SMS alert\n",
    "                sms_alert_queue.put(\"Gunshot Detected\")\n",
    "\n",
    "                # Saves a two-second sample as a WAV file\n",
    "                wave_file = wave.open(\"./recordings/Gunshot Sound Sample #\"\n",
    "                                      + str(gunshot_sound_counter) + \" (\"\n",
    "                                      + str(time_of_sample_occurrence) + \").wav\", \"wb\")\n",
    "                wave_file.setnchannels(audio_channels)\n",
    "                wave_file.setsampwidth(2)\n",
    "                wave_file.setframerate(22050)\n",
    "                wave_file.writeframes(modified_microphone_data.reshape(44100))\n",
    "                wave_file.close()\n",
    "\n",
    "                # Increments the counter for gunshot sound file names\n",
    "                gunshot_sound_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMS Alert Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_sms_alert():\n",
    "    # Continuously dispatches SMS alerts to a list of designated recipients\n",
    "    while True:\n",
    "        sms_alert_status = sms_alert_queue.get()\n",
    "        if sms_alert_status == \"Gunshot Detected\":\n",
    "            logger.debug(\"ALERT: A Gunshot Has Been Detected\")\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuring the Modem Connection\n",
    "    modem_port = '/dev/ttyUSB0'\n",
    "    modem_baudrate = 115200\n",
    "    modem_sim_pin = None  # SIM card PIN (if any)\n",
    "    \n",
    "    # Establishing a Connection to the SMS Modem\n",
    "    logger.debug(\"Initializing connection to modem...\")\n",
    "    modem = GsmModem(modem_port, modem_baudrate)\n",
    "    modem.smsTextMode = False\n",
    "    modem.connect(modem_sim_pin)\n",
    "    \n",
    "    # The SMS alert process will run indefinitely\n",
    "    while True:\n",
    "        sms_alert_status = sms_alert_queue.get()\n",
    "        if sms_alert_status == \"Gunshot Detected\":\n",
    "            try:\n",
    "                # At this point in execution, an attempt to send an SMS alert to local authorities will be made\n",
    "                modem.waitForNetworkCoverage(timeout = 86400)\n",
    "                message = \"(Testing) ALERT: A Gunshot Has Been Detected (Testing)\"\n",
    "                for number in designated_alert_recipients:\n",
    "                    modem.sendSms(number, message)\n",
    "                logger.debug(\" *** Sent out an SMS alert to all designated recipients *** \")\n",
    "            except:\n",
    "                logger.debug(\"ERROR: Unable to successfully send an SMS alert to the designated recipients.\")\n",
    "                pass\n",
    "            finally:\n",
    "                logger.debug(\" ** Finished evaluating an audio sample with the model ** \")\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opening the Microphone Audio Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = pyaudio.PyAudio()\n",
    "    \n",
    "stream = pa.open(format = audio_format,\n",
    "                 rate = audio_rate,\n",
    "                 channels = audio_channels,\n",
    "                 input_device_index = audio_device_index,\n",
    "                 frames_per_buffer = audio_frames_per_buffer,\n",
    "                 input = True,\n",
    "                 output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capturing Microphone Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.debug(\"--- Listening to Audio Stream ---\")\n",
    "\n",
    "audio_analysis_process = multiprocessing.Process(target = analyze_microphone_data)\n",
    "sms_alert_process = multiprocessing.Process(target = send_sms_alert)\n",
    "audio_analysis_queue = multiprocessing.Queue()\n",
    "sms_alert_queue = multiprocessing.Queue()\n",
    "audio_analysis_process.start()\n",
    "sms_alert_process.start()\n",
    "\n",
    "while True:\n",
    "    # Initializes an array of 16-bit signed integers along with a human-readable timestamp\n",
    "    sound_data = array('h')\n",
    "    current_time = time.ctime(time.time())\n",
    "    \n",
    "    # Loops through the stream and appends audio chunks to the frame array\n",
    "    for i in range(0, int(audio_rate / audio_frames_per_buffer * audio_sample_duration)):\n",
    "        sound_buffer = array('h', stream.read(audio_frames_per_buffer, exception_on_overflow = False))\n",
    "        if byteorder == 'big':\n",
    "            sound_buffer.byteswap()\n",
    "        sound_data.extend(sound_buffer)\n",
    "    \n",
    "    # Places a new sample of microphone data and a timestamp on the audio analysis queue\n",
    "    audio_analysis_queue.put(sound_data)\n",
    "    audio_analysis_queue.put(current_time)\n",
    "        \n",
    "    # Closes all finished processes   \n",
    "    multiprocessing.active_children()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing A Model with Sample Audio (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model_one(\"./models/gunshot_sound_model.h5\")\n",
    "training_sample, sr = librosa.load(\"./recordings/260600_8.wav\")\n",
    "training_sample = normalize(training_sample)\n",
    "number_of_missing_hertz = 44100 - len(training_sample)\n",
    "training_sample = np.array(training_sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "training_sample = training_sample.reshape(-1, 44100, 1)\n",
    "probabilities = model.predict(training_sample)\n",
    "logger.debug(\"The model-predicted probability values: \" + str(probabilities[0]))\n",
    "logger.debug(\"Model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities[:, 0])[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gunshot_detection",
   "language": "python",
   "name": "gunshot_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
