{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import librosa\n",
    "import logging\n",
    "import time\n",
    "import multiprocessing\n",
    "import audioop\n",
    "import wave\n",
    "import scipy.signal\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from queue import Queue\n",
    "from scipy.io import wavfile\n",
    "from datetime import timedelta as td\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from gsmmodem.modem import GsmModem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('debugger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.FileHandler('output.log')\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_format = pyaudio.paInt16\n",
    "audio_rate = 44100\n",
    "audio_channels = 1\n",
    "audio_device_index = 5\n",
    "audio_frames_per_buffer = 1024 * 4\n",
    "audio_sample_duration = 2\n",
    "audio_volume_threshold = 100\n",
    "duration_number_of_frames = int(audio_rate * audio_sample_duration)\n",
    "callback_is_running = True  # Determines whether the microphone stream is being captured\n",
    "callback_timeout = time.time() + 2.0 * 60  # 2 minutes from now\n",
    "callback_data = np.zeros(duration_number_of_frames, dtype='int16')  # Data buffer for the input waveform\n",
    "inference_model_confidence_threshold = 0.95\n",
    "max_audio_frame_int_value = 2 ** 15 - 1\n",
    "sound_normalization_threshold = 10 ** (-1.0 / 20)\n",
    "designated_alert_recipients = [\"8163449956\", \"9176202840\", \"7857642331\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Augmented Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load(\"/home/alexm/Datasets/gunshot_augmented_sound_labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarizing Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = np.array([(\"gun_shot\" if label == 1 else \"other\") for label in labels])\n",
    "label_binarizer = LabelBinarizer()\n",
    "labels = label_binarizer.fit_transform(labels)\n",
    "labels = np.hstack((labels, 1 - labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sound Post-Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sound_data):\n",
    "    normalization_factor = float(sound_normalization_threshold * max_audio_frame_int_value) / max(abs(i) for i in sound_data)\n",
    "    \n",
    "    # Averages the volume out\n",
    "    r = array('h')\n",
    "    for datum in sound_data:\n",
    "        r.append(int(datum * normalization_factor))\n",
    "    return np.array(r, dtype = np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librosa Wrapper Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stft(y, n_fft, hop_length, win_length):\n",
    "    return librosa.stft(y = y, n_fft = n_fft, hop_length = hop_length, win_length = win_length)\n",
    "\n",
    "\n",
    "def _istft(y, hop_length, win_length):\n",
    "    return librosa.istft(y, hop_length, win_length)\n",
    "\n",
    "\n",
    "def _amp_to_db(x):\n",
    "    return librosa.core.logamplitude(x, ref_power = 1.0, amin = 1e-20, top_db = 80.0)  # Librosa 0.4.2 functionality\n",
    "#     return librosa.core.amplitude_to_db(x, ref = 1.0, amin = 1e-20, top_db = 80.0)  # Librosa 0.6.3 functionality\n",
    "\n",
    "\n",
    "def _db_to_amp(x):\n",
    "    return librosa.core.perceptual_weighting(x, frequencies = 1.0)  # Librosa 0.4.2 functionality\n",
    "#     return librosa.core.db_to_amplitude(x, ref = 1.0)  # Librosa 0.6.3 functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Noise Reduction Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(audio_clip,\n",
    "                noise_clip,\n",
    "                n_grad_freq = 2,\n",
    "                n_grad_time = 4,\n",
    "                n_fft = 2048,\n",
    "                win_length = 2048,\n",
    "                hop_length = 512,\n",
    "                n_std_thresh = 1.5,\n",
    "                prop_decrease = 1.0,\n",
    "                verbose = False,\n",
    "                visual = False):\n",
    "    \n",
    "    \"\"\" Removes noise from audio based upon a clip containing only noise\n",
    "\n",
    "    Args:\n",
    "        audio_clip (array): The first parameter.\n",
    "        noise_clip (array): The second parameter.\n",
    "        n_grad_freq (int): how many frequency channels to smooth over with the mask.\n",
    "        n_grad_time (int): how many time channels to smooth over with the mask.\n",
    "        n_fft (int): number audio of frames between STFT columns.\n",
    "        win_length (int): Each frame of audio is windowed by `window()`. The window will be of length `win_length` and then padded with zeros to match `n_fft`..\n",
    "        hop_length (int):number audio of frames between STFT columns.\n",
    "        n_std_thresh (int): how many standard deviations louder than the mean dB of the noise (at each frequency level) to be considered signal\n",
    "        prop_decrease (float): To what extent should you decrease noise (1 = all, 0 = none)\n",
    "        visual (bool): Whether to plot the steps of the algorithm\n",
    "\n",
    "    Returns:\n",
    "        array: The recovered signal with noise subtracted\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        start = time.time()\n",
    "        \n",
    "    # Takes a STFT over the noise sample\n",
    "    noise_stft = _stft(noise_clip, n_fft, hop_length, win_length)\n",
    "    noise_stft_db = _amp_to_db(np.abs(noise_stft))  # Converts the sample units to dB\n",
    "    \n",
    "    # Calculates statistics over the noise sample\n",
    "    mean_freq_noise = np.mean(noise_stft_db, axis = 1)\n",
    "    std_freq_noise = np.std(noise_stft_db, axis = 1)\n",
    "    noise_thresh = mean_freq_noise + std_freq_noise * n_std_thresh\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"STFT on noise:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Takes a STFT over the signal sample\n",
    "    sig_stft = _stft(audio_clip, n_fft, hop_length, win_length)\n",
    "    sig_stft_db = _amp_to_db(np.abs(sig_stft))\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"STFT on signal:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Calculates value to which to mask dB\n",
    "    mask_gain_dB = np.min(_amp_to_db(np.abs(sig_stft)))\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Noise Threshold & Mask Gain in dB: \", noise_thresh, mask_gain_dB)\n",
    "    \n",
    "    # Creates a smoothing filter for the mask in time and frequency\n",
    "    smoothing_filter = np.outer(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(0, 1, n_grad_freq + 1, endpoint = False),\n",
    "                np.linspace(1, 0, n_grad_freq + 2),\n",
    "            ]\n",
    "        )[1:-1],\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(0, 1, n_grad_time + 1, endpoint = False),\n",
    "                np.linspace(1, 0, n_grad_time + 2),\n",
    "            ]\n",
    "        )[1:-1]\n",
    "    )\n",
    "    \n",
    "    smoothing_filter = smoothing_filter / np.sum(smoothing_filter)\n",
    "    \n",
    "    # Calculates the threshold for each frequency/time bin\n",
    "    db_thresh = np.repeat(np.reshape(noise_thresh, [1, len(mean_freq_noise)]),\n",
    "                          np.shape(sig_stft_db)[1],\n",
    "                          axis = 0).T\n",
    "    \n",
    "    # Masks segment if the signal is above the threshold\n",
    "    sig_mask = sig_stft_db < db_thresh\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Masking:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Convolves the mask with a smoothing filter\n",
    "    sig_mask = scipy.signal.fftconvolve(sig_mask, smoothing_filter, mode=\"same\")\n",
    "    sig_mask = sig_mask * prop_decrease\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Mask convolution:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Masks the signal\n",
    "    sig_stft_db_masked = (sig_stft_db * (1 - sig_mask)\n",
    "                          + np.ones(np.shape(mask_gain_dB))\n",
    "                          * mask_gain_dB * sig_mask)  # Masks real\n",
    "    \n",
    "    sig_imag_masked = np.imag(sig_stft) * (1 - sig_mask)\n",
    "    sig_stft_amp = (_db_to_amp(sig_stft_db_masked) * np.sign(sig_stft)) + (1j * sig_imag_masked)\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Mask application:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Recovers the signal\n",
    "    recovered_signal = _istft(sig_stft_amp, hop_length, win_length)\n",
    "    recovered_spec = _amp_to_db(\n",
    "        np.abs(_stft(recovered_signal, n_fft, hop_length, win_length))\n",
    "    )\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Signal recovery:\", td(seconds=time.time() - start))\n",
    "        \n",
    "    # Returns noise-reduced audio sample\n",
    "    return recovered_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Noise Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_sample_wav = \"./noise_reduction/Noise Sample - Alex's Laptop.wav\"\n",
    "noise_sample_rate, noise_sample = wavfile.read(noise_sample_wav)\n",
    "noise_clip = noise_sample[14000:18000]  # Finding a clip with just noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC (AUC) metric - Uses the import \"from tensorflow.keras import backend as K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Time-Series Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_one(weights_file):\n",
    "    # Initializing 1D Time-Series Model Parameters\n",
    "    drop_out_rate = 0.1\n",
    "    learning_rate = 0.001\n",
    "    number_of_epochs = 100\n",
    "    number_of_classes = 2\n",
    "    batch_size = 32\n",
    "    optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "    input_shape = (44100, 1)\n",
    "    input_tensor = Input(shape = input_shape)\n",
    "    metrics = [auc, \"accuracy\"]\n",
    "    \n",
    "    # Reconstructing 1D Time-Series Model\n",
    "    x = layers.Conv1D(16, 9, activation = \"relu\", padding = \"same\")(input_tensor)\n",
    "    x = layers.Conv1D(16, 9, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.MaxPool1D(16)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(256, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.Conv1D(256, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.GlobalMaxPool1D()(x)\n",
    "    x = layers.Dropout(rate = (drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "    x = layers.Dense(64, activation = \"relu\")(x)\n",
    "    x = layers.Dense(1028, activation = \"relu\")(x)\n",
    "    \n",
    "    # Compiling 1D Time-Series Model\n",
    "    output_tensor = layers.Dense(number_of_classes, activation = \"softmax\")(x)\n",
    "    model = tf.keras.Model(input_tensor, output_tensor)\n",
    "    model.compile(optimizer = optimizer, loss = keras.losses.binary_crossentropy, metrics = metrics)\n",
    "    \n",
    "    # Loading 1D Time-Series Model Weights\n",
    "    model.load_weights(weights_file)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D Spectrogram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_two(weights_file):\n",
    "    # 2D Spectrogram Model Parameters\n",
    "    input_shape = (128, 87, 1)\n",
    "    input_tensor = Input(shape = input_shape)\n",
    "    learning_rate = 0.001\n",
    "    optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "    filter_size = (3,3)\n",
    "    maxpool_size = (3,3)\n",
    "    activation = \"relu\"\n",
    "    drop_out_rate = 0.1\n",
    "    number_of_classes = 2\n",
    "    metrics = [auc, \"accuracy\"]\n",
    "    \n",
    "    # Reconstructing 2D Spectrogram Model\n",
    "    x = layers.Conv2D(16, filter_size, activation = activation, padding = \"same\")(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(32, filter_size, activation = activation, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, filter_size, activation = activation, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(256, filter_size, activation = activation, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalMaxPool2D()(x)\n",
    "    x = layers.Dropout(rate = (drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "    x = layers.Dense(64, activation = activation)(x)\n",
    "    x = layers.Dense(1028, activation = activation)(x)\n",
    "    \n",
    "    # Compiling 2D Spectrogram Model\n",
    "    output_tensor = layers.Dense(number_of_classes, activation = \"softmax\")(x)\n",
    "    spec_model = tf.keras.Model(input_tensor, output_tensor)\n",
    "    spec_model.compile(optimizer = optimizer, loss = keras.losses.binary_crossentropy, metrics = metrics)\n",
    "\n",
    "    # Loading 2D Spectrogram Model Weights\n",
    "    spec_model.load_weights(weights_file)\n",
    "    \n",
    "    return spec_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing Inference: A main process which adds two second samples of microphone data to the audio analysis queue; An audio analysis process which detects the presence of gunshot sounds in samples retrieved from the audio analysis queue; And an SMS alert process which dispatches groups of messages to designated recipients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Multiprocess Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Analysis Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_microphone_data():\n",
    "    # Loading 1D Time-Series Model\n",
    "    model = load_model_one(\"./models/gunshot_sound_model.h5\")\n",
    "    \n",
    "    # Loading 2D Spectrogram Model\n",
    "#     model = load_model_two(\"./models/gunshot_sound_model_spectrograph_model.h5\")\n",
    "    \n",
    "    # An iterator variable for counting the number of gunshot sounds detected\n",
    "    gunshot_sound_counter = 1\n",
    "    \n",
    "    # The audio analysis process will run indefinitely\n",
    "    while True:\n",
    "        # Gets a sample and its timestamp from the audio analysis queue\n",
    "        microphone_data = np.array(audio_analysis_queue.get(), dtype = np.int16)\n",
    "        time_of_sample_occurrence = audio_analysis_queue.get()\n",
    "        \n",
    "        # Outputs the current sample's maximum frequency value\n",
    "        maximum_frequency_value = max(microphone_data)\n",
    "        logger.debug(\"The maximum frequency value of a given sample: \" + str(maximum_frequency_value))\n",
    "        \n",
    "        # Determines whether a given sample potentially contains a gunshot\n",
    "        if maximum_frequency_value >= audio_volume_threshold:\n",
    "        \n",
    "            # Post-processes the microphone data\n",
    "            modified_microphone_data = librosa.resample(y = microphone_data, orig_sr = audio_rate, target_sr = 22050)\n",
    "            modified_microphone_data = normalize(modified_microphone_data)\n",
    "#             modified_microphone_data = remove_noise(audio_clip = modified_microphone_data, noise_clip = noise_clip)  # As a substitute for normalization\n",
    "#             number_of_missing_sample_hertz = 44100 - len(modified_microphone_data)\n",
    "#             if number_of_missing_sample_hertz > 0:\n",
    "#                 modified_microphone_data = np.array(modified_microphone_data.tolist() + [0 for i in range(number_of_missing_sample_hertz)])\n",
    "            modified_microphone_data = modified_microphone_data[:44100]\n",
    "            modified_microphone_data = modified_microphone_data.reshape(-1, 44100, 1)\n",
    "\n",
    "            # Passes a given audio sample into the model for prediction\n",
    "            probabilities = model.predict(modified_microphone_data)\n",
    "            logger.debug(\"The model-predicted probability values: \" + str(probabilities[0]))\n",
    "            logger.debug(\"Model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities[:, 0])[0])\n",
    "\n",
    "            # Determines if a gunshot sound was detected by the model\n",
    "            if (probabilities[0][1] >= inference_model_confidence_threshold):\n",
    "                # Sends out an SMS alert\n",
    "                sms_alert_queue.put(\"Gunshot Detected\")\n",
    "\n",
    "                # Saves a two-second sample as a WAV file\n",
    "                wave_file = wave.open(\"./recordings/Gunshot Sound Sample #\"\n",
    "                                      + str(gunshot_sound_counter) + \" (\"\n",
    "                                      + str(time_of_sample_occurrence) + \").wav\", \"wb\")\n",
    "                wave_file.setnchannels(audio_channels)\n",
    "                wave_file.setsampwidth(2)\n",
    "                wave_file.setframerate(22050)\n",
    "                wave_file.writeframes(modified_microphone_data.reshape(44100))\n",
    "                wave_file.close()\n",
    "\n",
    "                # Increments the counter for gunshot sound file names\n",
    "                gunshot_sound_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMS Alert Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_sms_alert():\n",
    "    # Continuously dispatches SMS alerts to a list of designated recipients\n",
    "    while True:\n",
    "        sms_alert_status = sms_alert_queue.get()\n",
    "        if sms_alert_status == \"Gunshot Detected\":\n",
    "            logger.debug(\"ALERT: A Gunshot Has Been Detected\")\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuring the Modem Connection\n",
    "    modem_port = '/dev/ttyUSB0'\n",
    "    modem_baudrate = 115200\n",
    "    modem_sim_pin = None  # SIM card PIN (if any)\n",
    "    \n",
    "    # Establishing a Connection to the SMS Modem\n",
    "    logger.debug(\"Initializing connection to modem...\")\n",
    "    modem = GsmModem(modem_port, modem_baudrate)\n",
    "    modem.smsTextMode = False\n",
    "    modem.connect(modem_sim_pin)\n",
    "    \n",
    "    # The SMS alert process will run indefinitely\n",
    "    while True:\n",
    "        sms_alert_status = sms_alert_queue.get()\n",
    "        if sms_alert_status == \"Gunshot Detected\":\n",
    "            try:\n",
    "                # At this point in execution, an attempt to send an SMS alert to local authorities will be made\n",
    "                modem.waitForNetworkCoverage(timeout = 86400)\n",
    "                message = \"(Testing) ALERT: A Gunshot Has Been Detected (Testing)\"\n",
    "                for number in designated_alert_recipients:\n",
    "                    modem.sendSms(number, message)\n",
    "                logger.debug(\" *** Sent out an SMS alert to all designated recipients *** \")\n",
    "            except:\n",
    "                logger.debug(\"ERROR: Unable to successfully send an SMS alert to the designated recipients.\")\n",
    "                pass\n",
    "            finally:\n",
    "                logger.debug(\" ** Finished evaluating an audio sample with the model ** \")\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Callback Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_queue = Queue()\n",
    "\n",
    "def callback(input_data, frame_count, time_info, status):\n",
    "    global callback_is_running, callback_timeout, callback_data, audio_volume_threshold\n",
    "    \n",
    "    if time.time() > callback_timeout:\n",
    "        callback_is_running = False  \n",
    "    data0 = np.frombuffer(input_data, dtype = 'int16')\n",
    "    \n",
    "    if np.abs(data0).mean() < audio_volume_threshold:\n",
    "        logger.debug(\"Audio volume was below threshold...\")\n",
    "        return (input_data, pyaudio.paContinue)\n",
    "    else:\n",
    "        logger.debug(\"Audio volume was above threshold...\")\n",
    "    callback_data = np.append(callback_data, data0)    \n",
    "    \n",
    "    if len(callback_data) > duration_number_of_frames:\n",
    "        callback_data = callback_data[-duration_number_of_frames:]\n",
    "        callback_queue.put(callback_data)  # Processes data asynchronously by sending it to a queue\n",
    "    return (input_data, pyaudio.paContinue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opening the Microphone Audio Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = pyaudio.PyAudio()\n",
    "\n",
    "stream = pa.open(format = audio_format,\n",
    "                 rate = audio_rate,\n",
    "                 channels = audio_channels,\n",
    "                 input_device_index = audio_device_index,\n",
    "                 frames_per_buffer = audio_frames_per_buffer,\n",
    "                 input = True,\n",
    "                 output = True,\n",
    "                 stream_callback = callback)\n",
    "\n",
    "stream.start_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capturing Microphone Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.debug(\"--- Listening to Audio Stream ---\")\n",
    "\n",
    "audio_analysis_process = multiprocessing.Process(target = analyze_microphone_data)\n",
    "sms_alert_process = multiprocessing.Process(target = send_sms_alert)\n",
    "audio_analysis_queue = multiprocessing.Queue()\n",
    "sms_alert_queue = multiprocessing.Queue()\n",
    "audio_analysis_process.start()\n",
    "sms_alert_process.start()\n",
    "\n",
    "try:\n",
    "    while callback_is_running:\n",
    "        # Fetches a new sample of microphone data from the audio stream\n",
    "        sound_data = callback_queue.get()\n",
    "        logger.debug(str(sound_data))\n",
    "        current_time = time.ctime(time.time())\n",
    "\n",
    "        # Places a new sample of microphone data and a timestamp on the audio analysis queue\n",
    "        audio_analysis_queue.put(sound_data)\n",
    "        audio_analysis_queue.put(current_time)\n",
    "\n",
    "        # Closes all finished processes   \n",
    "        multiprocessing.active_children()\n",
    "    \n",
    "except (KeyboardInterrupt, SystemExit):\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    callback_timeout = time.time()\n",
    "    callback_is_running = False\n",
    "    pa.terminate()\n",
    "    \n",
    "stream.stop_stream()\n",
    "stream.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing A Model with Sample Audio (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model_one(\"./models/gunshot_sound_model.h5\")\n",
    "# training_sample, sr = librosa.load(\"./recordings/260600_8.wav\")\n",
    "# training_sample = normalize(training_sample)\n",
    "# number_of_missing_hertz = 44100 - len(training_sample)\n",
    "# training_sample = np.array(training_sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "# training_sample = training_sample.reshape(-1, 44100, 1)\n",
    "# probabilities = model.predict(training_sample)\n",
    "# logger.debug(\"The model-predicted probability values: \" + str(probabilities[0]))\n",
    "# logger.debug(\"Model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities[:, 0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gunshot_detection",
   "language": "python",
   "name": "gunshot_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
