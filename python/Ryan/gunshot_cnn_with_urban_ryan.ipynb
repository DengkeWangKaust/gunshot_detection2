{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Directory \n",
    "import glob\n",
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "import librosa\n",
    "\n",
    "# Dimension Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "\n",
    "# Data Pre-processing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import cv2\n",
    "\n",
    "# Configuration\n",
    "#py.init_notebook_mode(connected=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=[]\n",
    "labels = []\n",
    "sample_slice_iteration = 0\n",
    "\n",
    "gunshot_sound_dir = \"C:\\\\Users\\\\hosle\\\\Documents\\\\_REU2019\\\\gunshot\\\\\"\n",
    "\n",
    "for file in os.listdir(gunshot_sound_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        sample, sample_rate = librosa.load(gunshot_sound_dir + file)\n",
    "        if (sample.size <= 44100):\n",
    "            sample_slice = np.zeros(44100)\n",
    "            sample_slice[0:sample.size] = sample\n",
    "            label = 1\n",
    "            sample_slice_iteration += 1\n",
    "            if np.max(abs(sample_slice)) < 0.25:\n",
    "                label = 0\n",
    "\n",
    "            samples.append(sample_slice)\n",
    "            labels.append(label)\n",
    "            \n",
    "        for i in range(0, sample.size - 44100, 44100):\n",
    "            sample_slice = sample[i : i + 44100]\n",
    "            label = 1\n",
    "            sample_slice_iteration += 1\n",
    "            if np.max(abs(sample_slice)) < 0.25:\n",
    "                label = 0\n",
    "\n",
    "            samples.append(sample_slice)\n",
    "            labels.append(label)\n",
    "        \n",
    "glassbreak_sound_dir = \"C:\\\\Users\\\\hosle\\\\Documents\\\\_REU2019\\\\glassbreak\\\\\"\n",
    "\n",
    "print(\"...Switching to glassbreak sounds...\")\n",
    "\n",
    "for file in os.listdir(glassbreak_sound_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        sample, sample_rate = librosa.load(glassbreak_sound_dir + file)\n",
    "        if (sample.size <= 44100):\n",
    "            sample_slice = np.zeros(44100)\n",
    "            sample_slice[0:sample.size] = sample\n",
    "            label = 0\n",
    "            sample_slice_iteration += 1\n",
    "            if np.max(abs(sample_slice)) < 0.5:\n",
    "                label = 0\n",
    "\n",
    "            samples.append(sample_slice)\n",
    "            labels.append(label)\n",
    "            \n",
    "        for i in range(0, sample.size - 44100, 44100):\n",
    "            sample_slice = sample[i : i + 44100]\n",
    "            label = 0\n",
    "            sample_slice_iteration += 1\n",
    "            if np.max(abs(sample_slice)) < 0.5:\n",
    "                label = 0\n",
    "\n",
    "            samples.append(sample_slice)\n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"samples.npy\", samples)\n",
    "np.save(\"labels.npy\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = \"C:\\\\Users\\\\hosle\\\\Documents\\\\_REU2019\\\\_project\\\\gunshot_detection\\\\Train\\\\\"\n",
    "dr = os.listdir(mypath)\n",
    "for i in range(len(dr)):\n",
    "    dr[i] = int(dr[i][:-4])\n",
    "dr = np.sort(dr)\n",
    "files = np.zeros(len(dr)).astype('str')\n",
    "for i in range(len(dr)):\n",
    "    files[i] = str(dr[i]) + '.wav'\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read in the csv file of descriptors for all other urban sounds\n",
    "sound_types = pd.read_csv(\"C:\\\\Users\\\\hosle\\\\Documents\\\\_REU2019\\\\_project\\\\gunshot_detection\\\\train.csv\")\n",
    "print(sound_types.loc[0,'Class'])\n",
    "\n",
    "j=0\n",
    "count = 0\n",
    "#read in all of the wav files similar to above\n",
    "urban_sound_dir = \"C:\\\\Users\\\\hosle\\\\Documents\\\\_REU2019\\\\_project\\\\gunshot_detection\\\\Train\\\\\"\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith(\".wav\"):\n",
    "        count += 1\n",
    "        sample, sample_rate = librosa.load(urban_sound_dir + file)\n",
    "        if (count % 100 == 0):\n",
    "            print (count)\n",
    "        if (sample.size <= 44100):\n",
    "            sample_slice = np.zeros(44100)\n",
    "            sample_slice[0:sample.size] = sample\n",
    "            if(sound_types.loc[j, 'Class'] == \"gun_shot\"):\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "            sample_slice_iteration += 1\n",
    "            if np.max(abs(sample_slice)) < 0.25:\n",
    "                label = 0\n",
    "\n",
    "            samples.append(sample_slice)\n",
    "            labels.append(label)\n",
    "\n",
    "\n",
    "        for i in range(0, sample.size - 44100, 44100):\n",
    "            sample_slice = sample[i : i + 44100]\n",
    "            if(sound_types.loc[j, 'Class'] == \"gun_shot\"):\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "            sample_slice_iteration += 1\n",
    "            if np.max(abs(sample_slice)) < 0.25:\n",
    "                label = 0\n",
    "\n",
    "            samples.append(sample_slice)\n",
    "            labels.append(label)\n",
    "        j +=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fireworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list(np.load(\"samples.npy\"))\n",
    "labels = list(np.load(\"labels.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_slice_iteration = 0\n",
    "\n",
    "sound_dir = \"C:\\\\Users\\\\hosle\\\\Documents\\\\_REU2019\\\\_project\\\\gunshot_detection\\\\fireworks\\\\\"\n",
    "\n",
    "for file in os.listdir(sound_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        sample, sample_rate = librosa.load(sound_dir + file)\n",
    "        if (sample.size <= 44100):\n",
    "            sample_slice = np.zeros(44100)\n",
    "            sample_slice[0:sample.size] = sample\n",
    "            label = 0\n",
    "            sample_slice_iteration += 1\n",
    "            if np.max(abs(sample_slice)) < 0.25:\n",
    "                label = 0\n",
    "\n",
    "            samples.append(sample_slice)\n",
    "            labels.append(label)\n",
    "            \n",
    "        for i in range(0, sample.size - 44100, 44100):\n",
    "            sample_slice = sample[i : i + 44100]\n",
    "            label = 0\n",
    "            sample_slice_iteration += 1\n",
    "            if np.max(abs(sample_slice)) < 0.25:\n",
    "                label = 0\n",
    "\n",
    "            samples.append(sample_slice)\n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(samples))\n",
    "i=450\n",
    "samp=samples[i]\n",
    "sr=2050\n",
    "print(np.max(abs(samp)))\n",
    "print(labels[i])\n",
    "ipd.Audio(samp, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"samples.npy\", samples)\n",
    "np.save(\"labels.npy\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load(\"samples.npy\")\n",
    "labels = np.load(\"labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_shift(wav):\n",
    "    start_ = int(np.random.uniform(-4800,4800))\n",
    "    if start_ >= 0:\n",
    "        wav_time_shift = np.r_[wav[start_:], np.random.uniform(-0.001,0.001, start_)]\n",
    "    else:\n",
    "        wav_time_shift = np.r_[np.random.uniform(-0.001,0.001, -start_), wav[:start_]]\n",
    "    return wav_time_shift\n",
    "\n",
    "def speed_change(wav):\n",
    "    speed_rate = np.random.uniform(0.7,1.3)\n",
    "    wav_speed_tune = cv2.resize(wav, (1, int(len(wav) * speed_rate))).squeeze()\n",
    "    #print('speed rate: %.3f' % speed_rate, '(lower is faster)')\n",
    "    if len(wav_speed_tune) < len(wav):\n",
    "        pad_len = len(wav) - len(wav_speed_tune)\n",
    "        wav_speed_tune = np.r_[np.random.uniform(-0.001,0.001,int(pad_len/2)),\n",
    "                               wav_speed_tune,\n",
    "                               np.random.uniform(-0.001,0.001,int(np.ceil(pad_len/2)))]\n",
    "    else: \n",
    "        cut_len = len(wav_speed_tune) - len(wav)\n",
    "        wav_speed_tune = wav_speed_tune[int(cut_len/2):int(cut_len/2)+len(wav)]\n",
    "    return wav_speed_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_labels = np.zeros((labels.shape[0]*3,))\n",
    "aug_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_samples = np.zeros((samples.shape[0]*3, samples.shape[1]))\n",
    "aug_labels = np.zeros((labels.shape[0]*3,))\n",
    "j = 0\n",
    "for i in range (0, len(aug_samples), 3):\n",
    "    aug_samples[i,:] = samples[j,:]\n",
    "    aug_samples[i+1,:] = time_shift(samples[j,:])\n",
    "    aug_samples[i+2,:] = speed_change(samples[j,:])\n",
    "    \n",
    "    aug_labels[i] = labels[j]\n",
    "    aug_labels[i+1] = labels[j]\n",
    "    aug_labels[i+2] = labels[j]\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"aug_samples.npy\", aug_samples)\n",
    "np.save(\"aug_labels.npy\", aug_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "samples = np.load(\"samples.npy\")\n",
    "labels = np.load(\"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 1:\n",
    "        l.append('gunshot')\n",
    "    else:\n",
    "        l.append('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.hstack((labels, 1 - labels))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    2 ... 6374 6375 6377] TEST: [   5    6    8 ... 6366 6373 6376]\n",
      "TRAIN: [   1    4    5 ... 6375 6376 6377] TEST: [   0    2    3 ... 6370 6371 6372]\n",
      "TRAIN: [   0    2    3 ... 6372 6373 6376] TEST: [   1    4   10 ... 6374 6375 6377]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "'''samples = aug_samples #np.array(samples)\n",
    "labels = aug_labels #np.array(labels)'''\n",
    "\n",
    "#labels = keras.utils.to_categorical(labels, 2)\n",
    "for train_index, test_index in kf.split(samples):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_wav, test_wav = samples[train_index], samples[test_index]\n",
    "    train_label, test_label = labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(data):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.waveplot(data, sr = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "lr = 0.001\n",
    "generations = 20000\n",
    "num_gens_to_wait = 250\n",
    "batch_size = 32\n",
    "drop_out_rate = 0.2\n",
    "input_shape = (44100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Conv1D add Channel\n",
    "train_wav = np.array(train_wav)\n",
    "test_wav = np.array(test_wav)\n",
    "train_wav = train_wav.reshape(-1,44100,1)\n",
    "test_wav = test_wav.reshape(-1,44100,1)\n",
    "#train_label = keras.utils.to_categorical(train_label, 2)\n",
    "#test_label = keras.utils.to_categorical(test_label, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC metric used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=input_shape)\n",
    "nclass = 2\n",
    "\n",
    "x = layers.Convolution1D(16, 9, activation=\"relu\", padding=\"same\")(input_tensor)\n",
    "x = layers.Convolution1D(16, 9, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool1D(16)(x)\n",
    "x = layers.Dropout(rate=0.1)(x)\n",
    "\n",
    "x = layers.Convolution1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Convolution1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool1D(8)(x)\n",
    "x = layers.Dropout(rate=0.1)(x)\n",
    "\n",
    "x = layers.Convolution1D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Convolution1D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dropout(rate=0.2)(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(1028, activation=\"relu\")(x)\n",
    "output_tensor = layers.Dense(nclass, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "opt = optimizers.Adam()#0.001, 0.001 / 100)\n",
    "\n",
    "model.compile(optimizer=opt, loss=keras.losses.binary_crossentropy, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 44100, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 44100, 16)         160       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 44100, 16)         2320      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2756, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2756, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 2756, 32)          1568      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 2756, 32)          3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 344, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 344, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 344, 128)          12416     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 344, 128)          49280     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1028)              66820     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 2058      \n",
      "=================================================================\n",
      "Total params: 145,982\n",
      "Trainable params: 145,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = '1Dcnngunglass.pkl' \n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_acc',\n",
    "                  patience=10,\n",
    "                  verbose=1,\n",
    "                  mode='max'),\n",
    "    \n",
    "    ModelCheckpoint(model_filename, monitor='val_acc',\n",
    "                    verbose=1,\n",
    "                    save_best_only=True,\n",
    "                    mode='max'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4252 samples, validate on 2126 samples\n",
      "Epoch 1/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.2101 - acc: 0.9323\n",
      "Epoch 00001: val_acc improved from -inf to 0.96849, saving model to 1Dcnngunglass.pkl\n",
      "4252/4252 [==============================] - 13s 3ms/sample - loss: 0.2093 - acc: 0.9325 - val_loss: 0.0819 - val_acc: 0.9685\n",
      "Epoch 2/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9744\n",
      "Epoch 00002: val_acc did not improve from 0.96849\n",
      "4252/4252 [==============================] - 12s 3ms/sample - loss: 0.0700 - acc: 0.9744 - val_loss: 0.0919 - val_acc: 0.9577\n",
      "Epoch 3/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9792\n",
      "Epoch 00003: val_acc did not improve from 0.96849\n",
      "4252/4252 [==============================] - 12s 3ms/sample - loss: 0.0561 - acc: 0.9791 - val_loss: 0.0774 - val_acc: 0.9675\n",
      "Epoch 4/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9851\n",
      "Epoch 00004: val_acc improved from 0.96849 to 0.97883, saving model to 1Dcnngunglass.pkl\n",
      "4252/4252 [==============================] - 12s 3ms/sample - loss: 0.0458 - acc: 0.9852 - val_loss: 0.0590 - val_acc: 0.9788\n",
      "Epoch 5/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9872\n",
      "Epoch 00005: val_acc did not improve from 0.97883\n",
      "4252/4252 [==============================] - 12s 3ms/sample - loss: 0.0343 - acc: 0.9871 - val_loss: 0.0643 - val_acc: 0.9760\n",
      "Epoch 6/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9872\n",
      "Epoch 00006: val_acc improved from 0.97883 to 0.98119, saving model to 1Dcnngunglass.pkl\n",
      "4252/4252 [==============================] - 12s 3ms/sample - loss: 0.0379 - acc: 0.9873 - val_loss: 0.0660 - val_acc: 0.9812\n",
      "Epoch 7/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9822\n",
      "Epoch 00007: val_acc improved from 0.98119 to 0.98354, saving model to 1Dcnngunglass.pkl\n",
      "4252/4252 [==============================] - 12s 3ms/sample - loss: 0.0466 - acc: 0.9824 - val_loss: 0.0466 - val_acc: 0.9835\n",
      "Epoch 8/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9920\n",
      "Epoch 00008: val_acc improved from 0.98354 to 0.98589, saving model to 1Dcnngunglass.pkl\n",
      "4252/4252 [==============================] - 12s 3ms/sample - loss: 0.0247 - acc: 0.9920 - val_loss: 0.0456 - val_acc: 0.9859\n",
      "Epoch 9/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9901\n",
      "Epoch 00009: val_acc did not improve from 0.98589\n",
      "4252/4252 [==============================] - 12s 3ms/sample - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0510 - val_acc: 0.9835\n",
      "Epoch 10/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9943\n",
      "Epoch 00010: val_acc did not improve from 0.98589\n",
      "4252/4252 [==============================] - 13s 3ms/sample - loss: 0.0207 - acc: 0.9939 - val_loss: 0.0707 - val_acc: 0.9765\n",
      "Epoch 11/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9960\n",
      "Epoch 00011: val_acc did not improve from 0.98589\n",
      "4252/4252 [==============================] - 12s 3ms/sample - loss: 0.0122 - acc: 0.9960 - val_loss: 0.0613 - val_acc: 0.9845\n",
      "Epoch 12/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9924\n",
      "Epoch 00012: val_acc did not improve from 0.98589\n",
      "4252/4252 [==============================] - 12s 3ms/sample - loss: 0.0221 - acc: 0.9925 - val_loss: 0.0640 - val_acc: 0.9817\n",
      "Epoch 13/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9957\n",
      "Epoch 00013: val_acc did not improve from 0.98589\n",
      "4252/4252 [==============================] - 12s 3ms/sample - loss: 0.0140 - acc: 0.9958 - val_loss: 0.0515 - val_acc: 0.9849\n",
      "Epoch 14/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9953\n",
      "Epoch 00014: val_acc did not improve from 0.98589\n",
      "4252/4252 [==============================] - 12s 3ms/sample - loss: 0.0135 - acc: 0.9953 - val_loss: 0.0630 - val_acc: 0.9845\n",
      "Epoch 15/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9983\n",
      "Epoch 00015: val_acc did not improve from 0.98589\n",
      "4252/4252 [==============================] - 12s 3ms/sample - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0631 - val_acc: 0.9854\n",
      "Epoch 16/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9936\n",
      "Epoch 00016: val_acc did not improve from 0.98589\n",
      "4252/4252 [==============================] - 12s 3ms/sample - loss: 0.0234 - acc: 0.9937 - val_loss: 0.0536 - val_acc: 0.9859\n",
      "Epoch 17/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9979\n",
      "Epoch 00017: val_acc did not improve from 0.98589\n",
      "4252/4252 [==============================] - 12s 3ms/sample - loss: 0.0060 - acc: 0.9979 - val_loss: 0.0565 - val_acc: 0.9840\n",
      "Epoch 18/100\n",
      "4224/4252 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9955\n",
      "Epoch 00018: val_acc did not improve from 0.98589\n",
      "4252/4252 [==============================] - 12s 3ms/sample - loss: 0.0115 - acc: 0.9955 - val_loss: 0.1070 - val_acc: 0.9751\n",
      "Epoch 00018: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bbb819e4e0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_wav, train_label, \n",
    "          validation_data=[test_wav, test_label],\n",
    "          batch_size=batch_size,\n",
    "          callbacks = callbacks,\n",
    "          epochs=100,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"1Dcnngunglass.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = \"C:\\\\Users\\\\hosle\\\\Downloads\\\\Metal Bang-SoundBible.com-672025076.wav\"\n",
    "#mypath = \"C:\\\\Users\\\\hosle\\\\Documents\\\\_REU2019\\\\extra\\\\320134.wav\"\n",
    "#mypath = \"C:\\\\Users\\\\hosle\\\\Documents\\\\_REU2019\\\\_project\\\\gunshot_detection\\\\fireworks\\\\56608__syna-max__fireworks-well-i-guess-you-missed-it.wav\"\n",
    "\n",
    "fire, sr = librosa.load(mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(fire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = []\n",
    "if (fire.size <= 44100):\n",
    "    sample_slice = np.zeros(44100)\n",
    "    sample_slice[0:fire.size] = fire\n",
    "    validation.append(sample_slice)\n",
    "\n",
    "for i in range(0, fire.size - 44100, 44100):\n",
    "    sample_slice = fire[i : i + 44100]\n",
    "    validation.append(sample_slice)\n",
    "    \n",
    "validation = np.array(validation)\n",
    "validation_1 = validation.reshape(-1,44100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = model.predict(validation_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred1 = lb.inverse_transform(val_pred[:, 0])\n",
    "print(len(val_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(val_pred1 == 'gunshot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[0, 1] = gunshot\n",
    "i = 0\n",
    "print(val_pred[i, :])\n",
    "print(val_pred1[i])\n",
    "show(validation [i])\n",
    "ipd.Audio(validation [i], rate=22050)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tflite converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"model.h5\" #\"gunshot_sound_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 18 variables.\n",
      "INFO:tensorflow:Converted 18 variables to const ops.\n",
      "\n",
      " made the converter using from_keras_model \n",
      "\n"
     ]
    }
   ],
   "source": [
    "converter = tf.contrib.lite.TFLiteConverter.from_keras_model_file(model_name)# custom_objects={'auc': auc})\n",
    "print(\"\\n made the converter using from_keras_model \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " did post training quantization \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#post-training quantization\n",
    "converter.post_training_quantize = True\n",
    "print(\" did post training quantization \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " converted successfully \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#convert\n",
    "tflite_model = converter.convert()\n",
    "print(\" converted successfully \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " saved successfully \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#save\n",
    "open(\"converted_gunshot_model_ptq.tflite\", \"wb\").write(tflite_model)\n",
    "print(\" saved successfully \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
