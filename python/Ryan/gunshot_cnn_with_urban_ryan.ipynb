{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Directory \n",
    "import glob\n",
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "import librosa\n",
    "\n",
    "# Dimension Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "\n",
    "# Data Pre-processing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "# Configuration\n",
    "#py.init_notebook_mode(connected=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(data):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.waveplot(data, sr = 16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=[]\n",
    "labels = []\n",
    "gunshot_frequency_threshold = 0.25\n",
    "sample_rate = 22050\n",
    "sample_rate_per_two_seconds = 44100\n",
    "input_shape = (sample_rate_per_two_seconds, 1)\n",
    "base_dir = \"C:\\\\Users\\\\hosle\\\\Documents\\\\_REU2019\\\\_project\\\\\"\n",
    "data_dir = base_dir + \"REU_Samples_and_Labels\\\\\"\n",
    "sound_data_dir = data_dir + \"Samples\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_types = pd.read_csv(data_dir + \"labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(sound_types.Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"...Parsing sound data...\")\n",
    "sound_file_id = 0\n",
    "sound_file_names = []\n",
    "count = 0\n",
    "\n",
    "for file in os.listdir(sound_data_dir):\n",
    "    if (count % 100 == 0):\n",
    "        print(count)\n",
    "        \n",
    "    count += 1\n",
    "    if file.endswith(\".wav\"):\n",
    "        # Adding 2 second-long samples to the list of samples\n",
    "        sound_file_id = int(re.search(r'\\d+', file).group())\n",
    "        sample, sample_rate = librosa.load(sound_data_dir + file, res_type='kaiser_fast')\n",
    "        prescribed_label = sound_types.loc[sound_types[\"ID\"] == sound_file_id, \"Class\"].values[0]\n",
    "        label = prescribed_label\n",
    "\n",
    "        if len(sample) <= sample_rate_per_two_seconds:\n",
    "            number_of_missing_hertz = sample_rate_per_two_seconds - len(sample)\n",
    "            padded_sample = np.array(sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "                \n",
    "            samples.append(padded_sample)\n",
    "            labels.append(label)\n",
    "            sound_file_names.append(file)\n",
    "        else:\n",
    "            for i in range(0, sample.size - sample_rate_per_two_seconds, sample_rate_per_two_seconds):\n",
    "                sample_slice = sample[i : i + sample_rate_per_two_seconds]\n",
    "\n",
    "                samples.append(sample_slice)\n",
    "                labels.append(label)\n",
    "                sound_file_names.append(file)\n",
    "\n",
    "print(\"The number of samples available for training is currently \" + str(len(samples)) + '.')\n",
    "print(\"The number of labels available for training is currently \" + str(len(labels)) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 7000\n",
    "show(samples[p])\n",
    "print(max(abs(samples[p])))\n",
    "print(labels[p])\n",
    "ipd.Audio(samples[p], rate=22050)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"samples.npy\", samples)\n",
    "np.save(\"labels.npy\", labels)\n",
    "np.save(\"file_names.npy\", sound_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list(np.load(\"samples.npy\"))\n",
    "labels = list(np.load(\"labels.npy\"))\n",
    "sound_file_names = np.load(\"file_names.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_data_dir = \"C:\\\\Users\\\\hosle\\\\Documents\\\\_REU2019\\\\_project\\\\other\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for file in os.listdir(sound_data_dir):\n",
    "    if (count % 100 == 0):\n",
    "        print(count)\n",
    "        \n",
    "    count += 1\n",
    "    # Adding 2 second-long samples to the list of samples\n",
    "    sample, sample_rate = librosa.load(sound_data_dir + file, res_type='kaiser_fast')\n",
    "    label = \"other\"\n",
    "\n",
    "    if len(sample) <= sample_rate_per_two_seconds:\n",
    "        number_of_missing_hertz = sample_rate_per_two_seconds - len(sample)\n",
    "        padded_sample = np.array(sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "\n",
    "        samples.append(padded_sample)\n",
    "        labels.append(label)\n",
    "        #sound_file_names.append(file)\n",
    "    else:\n",
    "        for i in range(0, sample.size - sample_rate_per_two_seconds, sample_rate_per_two_seconds):\n",
    "            sample_slice = sample[i : i + sample_rate_per_two_seconds]\n",
    "\n",
    "            samples.append(sample_slice)\n",
    "            labels.append(label)\n",
    "            #sound_file_names.append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples) - old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"samples.npy\", samples)\n",
    "np.save(\"labels.npy\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load(\"samples.npy\")\n",
    "labels = np.load(\"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['air_conditioner', 'car_horn', 'children_playing', 'dog_bark',\n",
       "       'drilling', 'engine_idling', 'fireworks', 'glassbreak', 'gun_shot',\n",
       "       'jackhammer', 'other', 'siren', 'street_music'], dtype='<U16')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = labels[labels != 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban = ['air_conditioner', 'car_horn', 'children_playing', 'dog_bark',\n",
    "       'drilling', 'engine_idling', 'jackhammer', 'siren', 'street_music']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(labels1)):\n",
    "    if labels1[i] in urban:\n",
    "        labels1[i] = 'urban'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fireworks', 'glassbreak', 'gun_shot', 'urban'], dtype='<U16')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_shift(wav):\n",
    "    start_ = int(np.random.uniform(-wav.shape[0] * 0.5, wav.shape[0] * 0.5))\n",
    "    if start_ >= 0:\n",
    "        wav_time_shift = np.r_[wav[start_:], np.random.uniform(-0.001, 0.001, start_)]\n",
    "    else:\n",
    "        wav_time_shift = np.r_[np.random.uniform(-0.001, 0.001, -start_), wav[:start_]]\n",
    "    return wav_time_shift\n",
    "    \n",
    "def change_pitch(wav, sample_rate):\n",
    "    magnitude = int(np.random.uniform(-10, 10))\n",
    "    wav_pitch_change = librosa.effects.pitch_shift(wav, sample_rate, magnitude)\n",
    "    return wav_pitch_change\n",
    "    \n",
    "def speed_change(wav):\n",
    "    speed_rate = np.random.uniform(0.7, 1.3)\n",
    "    wav_speed_tune = cv2.resize(wav, (1, int(len(wav) * speed_rate))).squeeze()\n",
    "    \n",
    "    if len(wav_speed_tune) < len(wav):\n",
    "        pad_len = len(wav) - len(wav_speed_tune)\n",
    "        wav_speed_tune = np.r_[np.random.uniform(-0.001, 0.001, int(pad_len / 2)),\n",
    "                               wav_speed_tune,\n",
    "                               np.random.uniform(-0.001, 0.001, int(np.ceil(pad_len / 2)))]\n",
    "    else: \n",
    "        cut_len = len(wav_speed_tune) - len(wav)\n",
    "        wav_speed_tune = wav_speed_tune[int(cut_len / 2) : int(cut_len / 2) + len(wav)]\n",
    "    return wav_speed_tune\n",
    "    \n",
    "def change_volume(wav, magnitude):\n",
    "    # 0 < x < 1 quieter; x = 1 identity; x > 1 louder\n",
    "    wav_volume_change = np.multiply(np.array([magnitude]), wav)\n",
    "    return wav_volume_change\n",
    "    \n",
    "def add_background(wav, bg_files):\n",
    "    sound_directory = \"C:\\\\Users\\\\hosle\\\\Documents\\\\_REU2019\\\\_project\\\\REU_Samples_and_Labels\\\\Samples\\\\\"\n",
    "    chosen_bg_file = bg_files[np.random.randint(len(bg_files))]\n",
    "\n",
    "    bg, sr = librosa.load(sound_directory + chosen_bg_file, res_type='kaiser_fast')\n",
    "    ceil = max((bg.shape[0] - wav.shape[0]), 1)\n",
    "    start_ = np.random.randint(ceil)\n",
    "    bg_slice = bg[start_ : start_ + wav.shape[0]]\n",
    "    if bg_slice.shape[0] < wav.shape[0]:\n",
    "        pad_len = wav.shape[0] - bg_slice.shape[0]\n",
    "        bg_slice = np.r_[np.random.uniform(-0.001, 0.001, int(pad_len / 2)), bg_slice, np.random.uniform(-0.001, 0.001, int(np.ceil(pad_len / 2)))]\n",
    "    wav_with_bg = wav * np.random.uniform(0.8, 1.2) + bg_slice * np.random.uniform(0, 0.5)\n",
    "    return wav_with_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_csv = \"C:\\\\Users\\\\hosle\\\\Documents\\\\_REU2019\\\\_project\\\\REU_Samples_and_Labels\\\\labels.csv\"\n",
    "sound_directory = \"C:\\\\Users\\\\hosle\\\\Documents\\\\_REU2019\\\\_project\\\\REU_Samples_and_Labels\\\\Samples\\\\\"\n",
    "sound_types = pd.read_csv(label_csv)\n",
    "bg_files = os.listdir(sound_directory)\n",
    "print(len(bg_files))\n",
    "\n",
    "for file in os.listdir(sound_directory):\n",
    "    if file.endswith(\".wav\"):\n",
    "        sound_file_id = int(re.search(r'\\d+', file).group())\n",
    "        prescribed_label = sound_types.loc[sound_types[\"ID\"] == sound_file_id, \"Class\"].values[0]\n",
    "        \n",
    "        if prescribed_label == \"gun_shot\":\n",
    "            bg_files.remove(file)\n",
    "            \n",
    "print(len(bg_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_augmentations = 4\n",
    "augmented_samples = np.zeros((samples.shape[0] * (number_of_augmentations + 1), samples.shape[1]))\n",
    "augmented_labels = np.zeros((labels.shape[0] * (number_of_augmentations + 1),)).astype('str')\n",
    "j = 0\n",
    "\n",
    "for i in range (0, len(augmented_samples), (number_of_augmentations + 1)):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    augmented_samples[i,:] = samples[j,:]\n",
    "    augmented_samples[i + 1,:] = time_shift(samples[j,:])\n",
    "    augmented_samples[i + 2,:] = change_pitch(samples[j,:], sample_rate)\n",
    "    augmented_samples[i + 3,:] = speed_change(samples[j,:])\n",
    "    augmented_samples[i + 4,:] = change_volume(samples[j,:], np.random.uniform())\n",
    "    ''' if labels[j] == 1:\n",
    "        augmented_samples[i + 5,:] = add_background(samples[j,:], bg_files) \n",
    "    else:\n",
    "        augmented_samples[i + 5,:] = add_background(samples[j,:], bg_files)\n",
    "        '''\n",
    "    \n",
    "    augmented_labels[i] = labels[j]\n",
    "    augmented_labels[i + 1] = labels[j]\n",
    "    augmented_labels[i + 2] = labels[j]\n",
    "    augmented_labels[i + 3] = labels[j]\n",
    "    augmented_labels[i + 4] = labels[j]\n",
    "    #augmented_labels[i + 5] = labels[j]\n",
    "    j += 1\n",
    "\n",
    "print(\"The number of samples available for training is currently \" + str(len(samples)) + '.')\n",
    "print(\"The number of labels available for training is currently \" + str(len(labels)) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"aug_samples.npy\", augmented_samples)\n",
    "np.save(\"aug_labels.npy\", augmented_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "samples = np.load(\"samples.npy\")\n",
    "labels = np.load(\"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.nbytes / (2**10)**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "'''samples = aug_samples #np.array(samples)\n",
    "labels = aug_labels #np.array(labels)'''\n",
    "\n",
    "#labels = keras.utils.to_categorical(labels, 2)\n",
    "for train_index, test_index in kf.split(samples):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_wav, test_wav = samples[train_index], samples[test_index]\n",
    "    train_label, test_label = labels[train_index], labels[test_index]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "lr = 0.001\n",
    "generations = 20000\n",
    "num_gens_to_wait = 250\n",
    "batch_size = 32\n",
    "drop_out_rate = 0.2\n",
    "input_shape = (44100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Conv1D add Channel\n",
    "#train_wav = np.array(train_wav)\n",
    "#test_wav = np.array(test_wav)\n",
    "train_wav = train_wav.reshape(-1,44100,1)\n",
    "test_wav = test_wav.reshape(-1,44100,1)\n",
    "#train_label = keras.utils.to_categorical(train_label, 2)\n",
    "#test_label = keras.utils.to_categorical(test_label, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC metric used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=input_shape)\n",
    "nclass = 13\n",
    "\n",
    "x = layers.Convolution1D(32, 9, activation=\"relu\", padding=\"same\")(input_tensor)\n",
    "x = layers.Convolution1D(32, 9, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool1D(16)(x)\n",
    "x = layers.Dropout(rate=0.1)(x)\n",
    "\n",
    "x = layers.Convolution1D(64, 9, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Convolution1D(64, 9, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool1D(4)(x)\n",
    "x = layers.Dropout(rate=0.1)(x)\n",
    "\n",
    "x = layers.Convolution1D(64, 9, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Convolution1D(64, 9, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool1D(4)(x)\n",
    "x = layers.Dropout(rate=0.1)(x)\n",
    "\n",
    "x = layers.Convolution1D(256, 9, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Convolution1D(256, 9, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dropout(rate=0.2)(x)\n",
    "\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dense(1028, activation=\"relu\")(x)\n",
    "output_tensor = layers.Dense(nclass, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "opt = optimizers.Adam(lr, lr / 100)\n",
    "\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = '1Dcnngunglass.pkl' \n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_acc',\n",
    "                  patience=10,\n",
    "                  verbose=1,\n",
    "                  mode='max'),\n",
    "    \n",
    "    ModelCheckpoint(model_filename, monitor='val_acc',\n",
    "                    verbose=1,\n",
    "                    save_best_only=True,\n",
    "                    mode='max'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_wav, train_label, \n",
    "          validation_data=[test_wav, test_label],\n",
    "          batch_size=batch_size,\n",
    "          callbacks = callbacks,\n",
    "          epochs=50,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"1Dcnngunglass.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = \"C:\\\\Users\\\\hosle\\\\Downloads\\\\felix_blume_fireworks_distant_new_years_eve_mexico.mp3\"\n",
    "#mypath = \"C:\\\\Users\\\\hosle\\\\Documents\\\\_REU2019\\\\extra\\\\260600.wav\"\n",
    "\n",
    "fire, sr = librosa.load(mypath, res_type='kaiser_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(fire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = []\n",
    "if (fire.size <= 44100):\n",
    "    sample_slice = np.zeros(44100)\n",
    "    sample_slice[0:fire.size] = fire\n",
    "    validation.append(sample_slice)\n",
    "\n",
    "for i in range(0, fire.size - 44100, 44100):\n",
    "    sample_slice = fire[i : i + 44100]\n",
    "    validation.append(sample_slice)\n",
    "    \n",
    "validation = np.array(validation)\n",
    "validation_1 = validation.reshape(-1,44100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = model.predict(validation_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred1 = lb.inverse_transform(val_pred)\n",
    "print(len(val_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(val_pred1 == 'gun_shot').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[0, 1] = gunshot\n",
    "i = 1\n",
    "print(np.round(val_pred[i, :], 3))\n",
    "print(val_pred1[i])\n",
    "show(validation [i])\n",
    "def show(data):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.waveplot(data, sr = 16000)\n",
    "ipd.Audio(validation [i], rate=22050)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tflite converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"model.h5\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.contrib.lite.TFLiteConverter.from_keras_model_file(model_name)# custom_objects={'auc': auc})\n",
    "print(\"\\n made the converter using from_keras_model \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post-training quantization\n",
    "converter.post_training_quantize = True\n",
    "print(\" did post training quantization \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert\n",
    "tflite_model = converter.convert()\n",
    "print(\" converted successfully \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "open(\"converted_gunshot_model_ptq.tflite\", \"wb\").write(tflite_model)\n",
    "print(\" saved successfully \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
