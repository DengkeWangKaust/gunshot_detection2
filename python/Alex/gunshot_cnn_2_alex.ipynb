{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### File Directory \n",
    "import glob\n",
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "\n",
    "### Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "import librosa\n",
    "\n",
    "### Dimension Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "### Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "### Data Pre-processing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import soundfile\n",
    "\n",
    "### Deep Learning\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Input, layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "### Configuration\n",
    "py.init_notebook_mode(connected=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Parsing gunshot sounds...\n",
      "Gunshot sound unrecognized by Librosa: [ 0.          0.          0.         ... -0.00243253  0.00497924\n",
      "  0.00153027]\n",
      "Gunshot sound unrecognized by Librosa: [ 0.          0.          0.         ... -0.00053873 -0.00050119\n",
      " -0.00052361]\n",
      "Gunshot sound unrecognized by Librosa: [ 0.          0.          0.         ... -0.00020621 -0.00021149\n",
      " -0.00021638]\n",
      "Gunshot sound unrecognized by Librosa: [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ... -6.69411165e-05\n",
      " -3.31310048e-06  4.10097273e-05]\n",
      "Gunshot sound unrecognized by Librosa: [0.         0.         0.         ... 0.00045294 0.00051964 0.00067115]\n",
      "The number of samples of available for training is currently 869.\n",
      "...Parsing sounds of glass breaking...\n",
      "The number of samples of available for training is currently 1217.\n"
     ]
    }
   ],
   "source": [
    "## Data Pre-Processing\n",
    "samples=[]\n",
    "sample_rates=[]\n",
    "labels = []\n",
    "sample_slice_iteration = 0\n",
    "gunshot_aggregator = {}\n",
    "glassbreak_aggregator = {}\n",
    "\n",
    "### Acquiring gunshot sound data\n",
    "gunshot_sound_dir = \"/home/alexm/Datasets/gunshot_data/gunshot/\"\n",
    "\n",
    "print(\"...Parsing gunshot sounds...\")\n",
    "\n",
    "for file in os.listdir(gunshot_sound_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        try:\n",
    "            sample, sample_rate = librosa.load(gunshot_sound_dir + file)\n",
    "            \n",
    "            #### Adding 2 second-long samples to the list of sample slices\n",
    "            if len(sample) <= 44100:\n",
    "                label = 2\n",
    "                gunshot_aggregator[sample_slice_iteration] = np.max(abs(sample_slice))\n",
    "                sample_slice_iteration += 1\n",
    "                if np.max(abs(sample)) < 0.25:\n",
    "                    label = 0\n",
    "\n",
    "                samples.append(sample)\n",
    "                sample_rates.append(sample_rate)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                for i in range(0, sample.size - 44100, 44100):\n",
    "                    sample_slice = sample[i : i + 44100]\n",
    "                    label = 2\n",
    "                    gunshot_aggregator[sample_slice_iteration] = np.max(abs(sample_slice))\n",
    "                    sample_slice_iteration += 1\n",
    "                    if np.max(abs(sample_slice)) < 0.25:\n",
    "                        label = 0\n",
    "\n",
    "                    samples.append(sample_slice)\n",
    "                    sample_rates.append(sample_rate)\n",
    "                    labels.append(label)\n",
    "        except:\n",
    "            sample, sample_rate = soundfile.read(gunshot_sound_dir + file)\n",
    "            print(\"Gunshot sound unrecognized by Librosa:\", sample)\n",
    "            pass\n",
    "\n",
    "print(\"The number of samples of available for training is currently \" + str(len(samples)) + '.')\n",
    "\n",
    "### Acquiring sound data from examples of glass breaking\n",
    "glassbreak_sound_dir = \"/home/alexm/Datasets/gunshot_data/glassbreak/\"\n",
    "\n",
    "print(\"...Parsing sounds of glass breaking...\")\n",
    "\n",
    "for file in os.listdir(glassbreak_sound_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        try:\n",
    "            sample, sample_rate = librosa.load(glassbreak_sound_dir + file)\n",
    "            \n",
    "            #### Adding 2 second-long samples to the list of sample slices\n",
    "            if len(sample) <= 44100:\n",
    "                label = 2\n",
    "                glassbreak_aggregator[sample_slice_iteration] = np.max(abs(sample_slice))\n",
    "                sample_slice_iteration += 1\n",
    "                if np.max(abs(sample)) < 0.25:\n",
    "                    label = 0\n",
    "\n",
    "                samples.append(sample)\n",
    "                sample_rates.append(sample_rate)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                for i in range(0, sample.size - 44100, 44100):\n",
    "                    sample_slice = sample[i : i + 44100]\n",
    "                    label = 2\n",
    "                    glassbreak_aggregator[sample_slice_iteration] = np.max(abs(sample_slice))\n",
    "                    sample_slice_iteration += 1\n",
    "                    if np.max(abs(sample_slice)) < 0.25:\n",
    "                        label = 0\n",
    "\n",
    "                    samples.append(sample_slice)\n",
    "                    sample_rates.append(sample_rate)\n",
    "                    labels.append(label)\n",
    "        except:\n",
    "            sample, sample_rate = soundfile.read(glassbreak_sound_dir + file)\n",
    "            print(\"Glassbreak sound unrecognized by Librosa:\", sample)\n",
    "            pass\n",
    "\n",
    "print(\"The number of samples of available for training is currently \" + str(len(samples)) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading in the CSV file of descriptors for all other kinds of urban sounds\n",
    "sound_types = pd.read_csv(\"/home/alexm/Datasets/urban_sound_labels.csv\")\n",
    "urban_aggregator = {}\n",
    "j=0\n",
    "\n",
    "### Reading in all of the urban sound data WAV files\n",
    "urban_sound_dir = \"/home/alexm/Datasets/urban_sounds/\"\n",
    "\n",
    "for file in os.listdir(urban_sound_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        try:\n",
    "            sample, sample_rate = librosa.load(urban_sound_dir + file)\n",
    "            for i in range(0, sample.size - 44100, 44100):\n",
    "                sample_slice = sample[i : i + 44100]\n",
    "                if(sound_types.loc[j, 'Class'] == \"gun_shot\"):\n",
    "                    label = 2\n",
    "                else:\n",
    "                    label = 0\n",
    "                urban_aggregator[sample_slice_iteration] = np.max(abs(sample_slice))\n",
    "                sample_slice_iteration += 1\n",
    "                if np.max(abs(sample_slice)) < 0.25:\n",
    "                    label = 0\n",
    "\n",
    "                samples.append(sample_slice)\n",
    "                sample_rates.append(sample_rate)\n",
    "                labels.append(label)\n",
    "            j +=1\n",
    "        except:\n",
    "            sample, sample_rate = soundfile.read(urban_sound_dir + file)\n",
    "            print(\"Urban sound not recognized by Librosa:\", sample)\n",
    "            pass\n",
    "\n",
    "print(\"The number of samples of available for training is currently \" + str(len(samples)) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional debugging after processing the data\n",
    "i=0  # You can change the value of 'i' to adjust which sample is being inspected.\n",
    "sample=samples[i]\n",
    "sample_rate=sample_rates[i]\n",
    "print(\"The number of samples available to the model for training is \" + str(len(samples)) + '.')\n",
    "print(\"The maximum frequency value in sample slice #\" + str(i) + \" is \" + str(np.max(abs(sample))) + '.')\n",
    "print(\"The label associated with sample slice #\" + str(i) + \" is \" + str(labels[i]) + '.')\n",
    "ipd.Audio(sample, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Arranging the data\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "samples = np.array(samples)\n",
    "labels = np.array(labels)\n",
    "for train_index, test_index in kf.split(samples):\n",
    "    train_wav, test_wav = samples[train_index], samples[test_index]\n",
    "    train_label, test_label = labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "drop_out_rate = 0.2\n",
    "input_shape = (44100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reshaping training & testing data\n",
    "train_wav = train_wav.reshape(-1,44100,1)\n",
    "test_wav = test_wav.reshape(-1,44100,1)\n",
    "train_label = keras.utils.to_categorical(train_label, 3)\n",
    "test_label = keras.utils.to_categorical(test_label, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional debugging of the training data's shape\n",
    "print(train_wav.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Architecture\n",
    "input_tensor = Input(shape=input_shape)\n",
    "\n",
    "x = layers.Conv1D(8, 11, padding='valid', activation='relu', strides=1)(input_tensor)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Conv1D(16, 7, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(4)(x)\n",
    "x = layers.Conv1D(32, 5, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(4)(x)\n",
    "x = layers.Conv1D(64, 5, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(6)(x)\n",
    "x = layers.Conv1D(128, 3, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(6)(x)\n",
    "x = layers.Conv1D(256, 3, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(6)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(100, activation='relu')(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.Dense(50, activation='relu')(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.Dense(20, activation='relu')(x)\n",
    "\n",
    "output_tensor = layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "             optimizer=keras.optimizers.Adam(lr = learning_rate),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configuring model properties\n",
    "model_filename = 'gunshot_sound_model.pkl'\n",
    "\n",
    "model_callbacks = [\n",
    "    EarlyStopping(monitor='val_acc',\n",
    "                  patience=10,\n",
    "                  verbose=1,\n",
    "                  mode='auto'),\n",
    "    \n",
    "    ModelCheckpoint(model_filename, monitor='val_acc',\n",
    "                    verbose=1,\n",
    "                    save_best_only=True,\n",
    "                    mode='auto'),\n",
    "]\n",
    "\n",
    "### Optional debugging of the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Recording the model\n",
    "model.load_weights(\"gunshot_sound_model.h5\")\n",
    "y_pred = np.round(model.predict(X_test))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional debugging of incorrectly-labeled examples\n",
    "Y_test_pred = model.predict(test_wav)\n",
    "y_predicted_classes_test = Y_test_pred.argmax(axis=-1)\n",
    "y_actual_classes_test= test_label.argmax(axis=-1)\n",
    "wrong_examples = np.nonzero(y_predicted_classes_test != y_actual_classes_test)\n",
    "print(wrong_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional debugging of an individual incorrectly-labeled example\n",
    "i=0\n",
    "samp=np.reshape(test_wav[i],44100,)\n",
    "sr=sample_rates[i]\n",
    "print(y_test[i],Y_test_pred[i])\n",
    "ipd.Audio(samp, rate=sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
