{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### File Directory \n",
    "import glob\n",
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "\n",
    "### Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "import librosa\n",
    "\n",
    "### Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "### Data Pre-processing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import soundfile\n",
    "\n",
    "### Deep Learning\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Input, layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "### Configuration\n",
    "py.init_notebook_mode(connected=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Pre-Processing\n",
    "samples=[]\n",
    "labels = []\n",
    "sampling_rate_per_two_seconds = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Parsing gunshot sounds...\n",
      "The number of samples of available for training is currently 874.\n",
      "The number of labels of available for training is currently 874.\n"
     ]
    }
   ],
   "source": [
    "### Acquiring gunshot sound data\n",
    "gunshot_sound_dir = \"/home/alexm/Datasets/gunshot_data/gunshot/\"\n",
    "print(\"...Parsing gunshot sounds...\")\n",
    "\n",
    "for file in os.listdir(gunshot_sound_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        try:\n",
    "            #### Adding 2 second-long samples to the list of samples\n",
    "            sample, sample_rate = librosa.load(gunshot_sound_dir + file)\n",
    "            \n",
    "            if len(sample) <= sampling_rate_per_two_seconds:\n",
    "                label = 1\n",
    "                number_of_missing_hertz = sampling_rate_per_two_seconds - len(sample)\n",
    "                padded_sample = np.array(sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "                if np.max(abs(sample)) < 0.25:\n",
    "                    label = 0\n",
    "                    \n",
    "                samples.append(padded_sample)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                for i in range(0, sample.size - sampling_rate_per_two_seconds, sampling_rate_per_two_seconds):\n",
    "                    sample_slice = sample[i : i + sampling_rate_per_two_seconds]\n",
    "                    label = 1\n",
    "                    if np.max(abs(sample_slice)) < 0.25:\n",
    "                        label = 0\n",
    "                        \n",
    "                    samples.append(sample_slice)\n",
    "                    labels.append(label)\n",
    "        except:\n",
    "            sample, sample_rate = soundfile.read(gunshot_sound_dir + file)\n",
    "            print(\"Gunshot sound unrecognized by Librosa:\", sample)\n",
    "            pass\n",
    "\n",
    "print(\"The number of samples of available for training is currently \" + str(len(samples)) + '.')\n",
    "print(\"The number of labels of available for training is currently \" + str(len(labels)) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Parsing sounds of glass breaking...\n",
      "The number of samples of available for training is currently 1222.\n",
      "The number of labels of available for training is currently 1222.\n"
     ]
    }
   ],
   "source": [
    "### Acquiring sound data from examples of glass breaking\n",
    "glassbreak_sound_dir = \"/home/alexm/Datasets/gunshot_data/glassbreak/\"\n",
    "print(\"...Parsing sounds of glass breaking...\")\n",
    "\n",
    "for file in os.listdir(glassbreak_sound_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        try:\n",
    "            #### Adding 2 second-long samples to the list of samples\n",
    "            sample, sample_rate = librosa.load(glassbreak_sound_dir + file)\n",
    "            \n",
    "            if len(sample) <= sampling_rate_per_two_seconds:\n",
    "                label = 1\n",
    "                number_of_missing_hertz = sampling_rate_per_two_seconds - len(sample)\n",
    "                padded_sample = np.array(sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "                if np.max(abs(sample)) < 0.25:\n",
    "                    label = 0\n",
    "\n",
    "                samples.append(padded_sample)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                for i in range(0, sample.size - sampling_rate_per_two_seconds, sampling_rate_per_two_seconds):\n",
    "                    sample_slice = sample[i : i + sampling_rate_per_two_seconds]\n",
    "                    label = 1\n",
    "                    if np.max(abs(sample_slice)) < 0.25:\n",
    "                        label = 0\n",
    "\n",
    "                    samples.append(sample_slice)\n",
    "                    labels.append(label)\n",
    "        except:\n",
    "            sample, sample_rate = soundfile.read(glassbreak_sound_dir + file)\n",
    "            print(\"Glassbreak sound unrecognized by Librosa:\", sample)\n",
    "            pass\n",
    "\n",
    "print(\"The number of samples of available for training is currently \" + str(len(samples)) + '.')\n",
    "print(\"The number of labels of available for training is currently \" + str(len(labels)) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Parsing urban sounds...\n"
     ]
    }
   ],
   "source": [
    "### Reading in the CSV file of descriptors for all other kinds of urban sounds\n",
    "sound_types = pd.read_csv(\"/home/alexm/Datasets/urban_sound_labels.csv\")\n",
    "\n",
    "### Reading in all of the urban sound data WAV files\n",
    "urban_sound_dir = \"/home/alexm/Datasets/urban_sounds/\"\n",
    "print(\"...Parsing urban sounds...\")\n",
    "urban_sound_iterator = 0\n",
    "\n",
    "for file in os.listdir(urban_sound_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        try:\n",
    "            #### Adding 2 second-long samples to the list of samples\n",
    "            sample, sample_rate = librosa.load(urban_sound_dir + file)\n",
    "            \n",
    "            if len(sample) <= sampling_rate_per_two_seconds:\n",
    "                label = 1\n",
    "                number_of_missing_hertz = sampling_rate_per_two_seconds - len(sample)\n",
    "                padded_sample = np.array(sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "                if sound_types.loc[urban_sound_iterator, 'Class'] != \"gun_shot\":\n",
    "                    label = 0\n",
    "                elif np.max(abs(sample)) < 0.25:\n",
    "                    label = 0\n",
    "\n",
    "                samples.append(padded_sample)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                for i in range(0, sample.size - sampling_rate_per_two_seconds, sampling_rate_per_two_seconds):\n",
    "                    sample_slice = sample[i : i + sampling_rate_per_two_seconds]\n",
    "                    if sound_types.loc[urban_sound_iterator, 'Class'] != \"gun_shot\":\n",
    "                        label = 0\n",
    "                    elif np.max(abs(sample_slice)) < 0.25:\n",
    "                        label = 0\n",
    "\n",
    "                    samples.append(sample_slice)\n",
    "                    labels.append(label)\n",
    "                    \n",
    "            urban_sound_iterator += 1\n",
    "        except:\n",
    "            sample, sample_rate = soundfile.read(urban_sound_dir + file)\n",
    "            print(\"Urban sound not recognized by Librosa:\", sample)\n",
    "            pass\n",
    "\n",
    "print(\"The number of samples of available for training is currently \" + str(len(samples)) + '.')\n",
    "print(\"The number of labels of available for training is currently \" + str(len(labels)) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Locally saving samples and labels as numpy array files\n",
    "np.save(\"/home/alexm/Datasets/gunshot_sound_samples.npy\", samples)\n",
    "np.save(\"/home/alexm/Datasets/gunshot_sound_labels.npy\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading in samples file and labels file as numpy arrays\n",
    "samples = np.load(\"/home/alexm/Datasets/gunshot_sound_samples.npy\")\n",
    "labels = np.load(\"/home/alexm/Datasets/gunshot_sound_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional debugging after processing the data\n",
    "i = 0  # You can change the value of 'i' to adjust which sample is being inspected.\n",
    "sample=samples[i]\n",
    "sample_rate=22050\n",
    "print(\"The number of samples available to the model for training is \" + str(len(samples)) + '.')\n",
    "print(\"The maximum frequency value in sample slice #\" + str(i) + \" is \" + str(np.max(abs(sample))) + '.')\n",
    "print(\"The label associated with sample slice #\" + str(i) + \" is \" + str(labels[i]) + '.')\n",
    "ipd.Audio(sample, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Arranging the data\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "samples = np.array(samples)\n",
    "labels = np.array(labels)\n",
    "for train_index, test_index in kf.split(samples):\n",
    "    train_wav, test_wav = samples[train_index], samples[test_index]\n",
    "    train_label, test_label = labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "drop_out_rate = 0.2\n",
    "input_shape = (sampling_rate_per_two_seconds, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reshaping training & testing data\n",
    "train_wav = train_wav.reshape(-1, sampling_rate_per_two_seconds, 1)\n",
    "test_wav = test_wav.reshape(-1, sampling_rate_per_two_seconds, 1)\n",
    "train_label = keras.utils.to_categorical(train_label, 2)\n",
    "test_label = keras.utils.to_categorical(test_label, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional debugging of the training data's shape\n",
    "print(train_wav.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Architecture\n",
    "input_tensor = Input(shape=input_shape)\n",
    "\n",
    "x = layers.Conv1D(8, 11, padding='valid', activation='relu', strides=1)(input_tensor)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Conv1D(16, 7, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(4)(x)\n",
    "x = layers.Conv1D(32, 5, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(4)(x)\n",
    "x = layers.Conv1D(64, 5, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(6)(x)\n",
    "x = layers.Conv1D(128, 3, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(6)(x)\n",
    "x = layers.Conv1D(256, 3, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(6)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(100, activation='relu')(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.Dense(50, activation='relu')(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.Dense(20, activation='relu')(x)\n",
    "\n",
    "output_tensor = layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "             optimizer=keras.optimizers.Adam(lr = learning_rate),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configuring model properties\n",
    "model_filename = 'gunshot_sound_model.pkl'\n",
    "\n",
    "model_callbacks = [\n",
    "    EarlyStopping(monitor='val_acc',\n",
    "                  patience=10,\n",
    "                  verbose=1,\n",
    "                  mode='auto'),\n",
    "    \n",
    "    ModelCheckpoint(model_filename, monitor='val_acc',\n",
    "                    verbose=1,\n",
    "                    save_best_only=True,\n",
    "                    mode='auto'),\n",
    "]\n",
    "\n",
    "training_generator = DataGenerator(train_wav, train_label)\n",
    "validation_generator = DataGenerator(test_wav, test_label)\n",
    "\n",
    "### Optional debugging of the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training & Recording the model\n",
    "model.fit_generator(generator = training_generator,\n",
    "                                validation_data = validation_generator,\n",
    "                                epochs = 50,\n",
    "                                callbacks = callbacks,\n",
    "                                verbose = 1,\n",
    "                                shuffle = True)\n",
    "\n",
    "model.load_weights(\"gunshot_sound_model.h5\")\n",
    "y_pred = np.round(model.predict(X_test))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "model.save_weights(\"gunshot_sound_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summarizing history for accuracy\n",
    "plt.plot(History.history['acc'])\n",
    "plt.plot(History.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "### Summarizing history for loss\n",
    "plt.plot(History.history['loss'])\n",
    "plt.plot(History.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional debugging of incorrectly-labeled examples\n",
    "Y_test_pred = model.predict(test_wav)\n",
    "y_predicted_classes_test = Y_test_pred.argmax(axis=-1)\n",
    "y_actual_classes_test= test_label.argmax(axis=-1)\n",
    "wrong_examples = np.nonzero(y_predicted_classes_test != y_actual_classes_test)\n",
    "print(wrong_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional debugging of an individual incorrectly-labeled example\n",
    "i = 0\n",
    "sample = np.reshape(test_wav[i], sampling_rate_per_two_seconds, )\n",
    "sample_rate = 22050\n",
    "print(y_test[i], Y_test_pred[i])\n",
    "ipd.Audio(sample, rate=sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
