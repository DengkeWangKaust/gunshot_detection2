{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Directory Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile\n",
    "import re\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of Imported Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "labels = []\n",
    "gunshot_frequency_threshold = 0.25\n",
    "sample_rate = 22050\n",
    "sample_rate_per_two_seconds = 44100\n",
    "base_dir = \"/home/alexm/Datasets/\"\n",
    "data_dir = base_dir + \"REU_Samples_and_Labels/\"\n",
    "sound_data_dir = data_dir + \"Samples/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the CSV file of descriptors for many kinds of sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_types = pd.read_csv(data_dir + \"labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in all of the sound data WAV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"...Parsing sound data...\")\n",
    "sound_file_id = 0\n",
    "sound_file_names = []\n",
    "\n",
    "for file in os.listdir(sound_data_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        try:\n",
    "            # Adding 2 second-long samples to the list of samples\n",
    "            sound_file_id = int(re.search(r'\\d+', file).group())\n",
    "            sample, sample_rate = librosa.load(sound_data_dir + file)\n",
    "            prescribed_label = sound_types.loc[sound_types[\"ID\"] == sound_file_id, \"Class\"].values[0]\n",
    "            \n",
    "            if len(sample) <= sample_rate_per_two_seconds:\n",
    "                label = 1\n",
    "                number_of_missing_hertz = sample_rate_per_two_seconds - len(sample)\n",
    "                padded_sample = np.array(sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "                if prescribed_label != \"gun_shot\":\n",
    "                    label = 0\n",
    "\n",
    "                samples.append(padded_sample)\n",
    "                labels.append(label)\n",
    "                sound_file_names.append(file)\n",
    "            else:\n",
    "                for i in range(0, sample.size - sample_rate_per_two_seconds, sample_rate_per_two_seconds):\n",
    "                    sample_slice = sample[i : i + sample_rate_per_two_seconds]\n",
    "                    if prescribed_label != \"gun_shot\":\n",
    "                        label = 0\n",
    "                    elif np.max(abs(sample_slice)) < gunshot_frequency_threshold:\n",
    "                        label = 0\n",
    "\n",
    "                    samples.append(sample_slice)\n",
    "                    labels.append(label)\n",
    "                    sound_file_names.append(file)\n",
    "\n",
    "        except:\n",
    "            sample, sample_rate = soundfile.read(sound_data_dir + file)\n",
    "            print(\"Sound(s) not recognized by Librosa:\", file)\n",
    "            pass\n",
    "\n",
    "print(\"The number of samples available for training is currently \" + str(len(samples)) + '.')\n",
    "print(\"The number of labels available for training is currently \" + str(len(labels)) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving samples and labels as numpy array files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(base_dir + \"gunshot_sound_samples.npy\", samples)\n",
    "np.save(base_dir + \"gunshot_sound_labels.npy\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading sample file and label file as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load(base_dir + \"gunshot_sound_samples.npy\")\n",
    "labels = np.load(base_dir + \"gunshot_sound_labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_shift(wav):\n",
    "    start_ = int(np.random.uniform(-7000, 7000))\n",
    "    if start_ >= 0:\n",
    "        wav_time_shift = np.r_[wav[start_:], np.random.uniform(-0.001, 0.001, start_)]\n",
    "    else:\n",
    "        wav_time_shift = np.r_[np.random.uniform(-0.001, 0.001, -start_), wav[:start_]]\n",
    "    return wav_time_shift\n",
    "    \n",
    "def change_pitch(wav, sample_rate):\n",
    "    magnitude = (np.random.uniform(-0.1, 0.1))\n",
    "    wav_pitch_change = librosa.effects.pitch_shift(wav, sample_rate, magnitude)\n",
    "    return wav_pitch_change\n",
    "    \n",
    "def speed_change(wav):\n",
    "    speed_rate = np.random.uniform(0.7, 1.3)\n",
    "    wav_speed_tune = cv2.resize(wav, (1, int(len(wav) * speed_rate))).squeeze()\n",
    "    \n",
    "    if len(wav_speed_tune) < len(wav):\n",
    "        pad_len = len(wav) - len(wav_speed_tune)\n",
    "        wav_speed_tune = np.r_[np.random.uniform(-0.0001, 0.0001, int(pad_len / 2)),\n",
    "                               wav_speed_tune,\n",
    "                               np.random.uniform(-0.0001, 0.0001, int(np.ceil(pad_len / 2)))]\n",
    "    else: \n",
    "        cut_len = len(wav_speed_tune) - len(wav)\n",
    "        wav_speed_tune = wav_speed_tune[int(cut_len / 2) : int(cut_len / 2) + len(wav)]\n",
    "    return wav_speed_tune\n",
    "    \n",
    "def change_volume(wav, magnitude):\n",
    "    # 0 < x < 1 quieter; x = 1 identity; x > 1 louder\n",
    "    wav_volume_change = np.multiply(np.array([magnitude]), wav)\n",
    "    return wav_volume_change\n",
    "    \n",
    "def add_background(wav, file, data_directory, label_to_avoid):\n",
    "    label_csv = data_directory + \"labels.csv\"\n",
    "    sound_types = pd.read_csv(label_csv)\n",
    "    sound_directory = data_directory + \"Samples/\"\n",
    "    bg_files = os.listdir(sound_directory)\n",
    "    bg_files.remove(file)\n",
    "    chosen_bg_file = bg_files[np.random.randint(len(bg_files))]\n",
    "    jndex = int(chosen_bg_file.split('.')[0])\n",
    "    while sound_types.loc[sound_types[\"ID\"] == jndex, \"Class\"].values[0] == label_to_avoid:\n",
    "        chosen_bg_file = bg_files[np.random.randint(len(bg_files))]\n",
    "        jndex = int(chosen_bg_file.split('.')[0])\n",
    "    bg, sr = librosa.load(sound_directory + chosen_bg_file)\n",
    "    ceil = max((bg.shape[0] - wav.shape[0]), 1)\n",
    "    start_ = np.random.randint(ceil)\n",
    "    bg_slice = bg[start_ : start_ + wav.shape[0]]\n",
    "    if bg_slice.shape[0] < wav.shape[0]:\n",
    "        pad_len = wav.shape[0] - bg_slice.shape[0]\n",
    "        bg_slice = np.r_[np.random.uniform(-0.001, 0.001, int(pad_len / 2)), bg_slice, np.random.uniform(-0.001, 0.001, int(np.ceil(pad_len / 2)))]\n",
    "    wav_with_bg = wav * np.random.uniform(0.8, 1.2) + bg_slice * np.random.uniform(0, 0.5)\n",
    "    return wav_with_bg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting data (i.e. time shifting, speed changing, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.array(samples)\n",
    "labels = np.array(labels)\n",
    "number_of_augmentations = 5\n",
    "augmented_samples = np.zeros((samples.shape[0] * (number_of_augmentations + 1), samples.shape[1]))\n",
    "augmented_labels = np.zeros((labels.shape[0] * (number_of_augmentations + 1),))\n",
    "j = 0\n",
    "\n",
    "for i in range (0, len(augmented_samples), (number_of_augmentations + 1)):\n",
    "    file = sound_file_names[j]\n",
    "    \n",
    "    augmented_samples[i,:] = samples[j,:]\n",
    "    augmented_samples[i + 1,:] = time_shift(samples[j,:])\n",
    "    augmented_samples[i + 2,:] = change_pitch(samples[j,:], sample_rate)\n",
    "    augmented_samples[i + 3,:] = speed_change(samples[j,:])\n",
    "    augmented_samples[i + 4,:] = change_volume(samples[j,:], np.random.uniform())\n",
    "    if labels[j] == 1:\n",
    "        augmented_samples[i + 5,:] = add_background(samples[j,:], file, data_dir, \"\") \n",
    "    else:\n",
    "        augmented_samples[i + 5,:] = add_background(samples[j,:], file, data_dir, \"gun_shot\")\n",
    "    \n",
    "    augmented_labels[i] = labels[j]\n",
    "    augmented_labels[i + 1] = labels[j]\n",
    "    augmented_labels[i + 2] = labels[j]\n",
    "    augmented_labels[i + 3] = labels[j]\n",
    "    augmented_labels[i + 4] = labels[j]\n",
    "    augmented_labels[i + 5] = labels[j]\n",
    "    j += 1\n",
    "\n",
    "samples = augmented_samples\n",
    "labels = augmented_labels\n",
    "\n",
    "print(\"The number of samples available for training is currently \" + str(len(samples)) + '.')\n",
    "print(\"The number of labels available for training is currently \" + str(len(labels)) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving augmented samples and labels as numpy array files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(base_dir + \"gunshot_augmented_sound_samples.npy\", samples)\n",
    "np.save(base_dir + \"gunshot_augmented_sound_labels.npy\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading augmented sample file and label file as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load(base_dir + \"gunshot_augmented_sound_samples.npy\")\n",
    "labels = np.load(base_dir + \"gunshot_augmented_sound_labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging after augmenting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0  # You can change the value of 'i' to adjust which sample is being inspected.\n",
    "sample = samples[i]\n",
    "print(\"The number of samples available to the model for training is \" + str(len(samples)) + '.')\n",
    "print(\"The maximum frequency value in sample slice #\" + str(i) + \" is \" + str(np.max(abs(sample))) + '.')\n",
    "print(\"The label associated with sample slice #\" + str(i) + \" is \" + str(labels[i]) + '.')\n",
    "ipd.Audio(sample, rate = sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Augmented Samples to Spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Spectrogram Conversion Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_spectrogram(data, sample_rate):\n",
    "    return np.array(librosa.feature.melspectrogram(y = data, sr = sample_rate))\n",
    "\n",
    "def save_spectrogram_as_png(spectrogram, index):\n",
    "    plt.interactive(False)\n",
    "    fig = plt.figure(figsize = [0.72, 0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    librosa.display.specshow(librosa.power_to_db(spectrogram, ref = np.max))\n",
    "    plt.savefig(\"~/Datasets/Spectrograms/\" + str(index) + \".png\", dpi = 400, bbox_inches = \"tight\", pad_inches = 0)\n",
    "\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratively Converting All Augmented Samples into Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectogram_index = 0\n",
    "\n",
    "for sample in samples:\n",
    "    spectrogram = convert_to_spectrogram(sample, sample_rate)\n",
    "    save_spectrogram_as_png(spectrogram, spectogram_index)\n",
    "    spectogram_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructuring the label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([(\"gun_shot\" if label == 1 else \"other\") for label in labels])\n",
    "label_binarizer = LabelBinarizer()\n",
    "labels = label_binarizer.fit_transform(labels)\n",
    "labels = np.hstack((labels, 1 - labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging of the label data's shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arranging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 3, shuffle = True)\n",
    "samples = np.array(samples)\n",
    "labels = np.array(labels)\n",
    "for train_index, test_index in kf.split(samples):\n",
    "    train_wav, test_wav = samples[train_index], samples[test_index]\n",
    "    train_label, test_label = labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping the sound data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wav = train_wav.reshape(-1, sample_rate_per_two_seconds, 1)\n",
    "test_wav = test_wav.reshape(-1, sample_rate_per_two_seconds, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging of the sound data's shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_wav.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(base_dir + \"gunshot_sound_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC (AUC) metric - Uses the import \"from tensorflow.keras import backend as K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_out_rate = 0.1\n",
    "learning_rate = 0.001\n",
    "number_of_epochs = 100\n",
    "number_of_classes = 2\n",
    "batch_size = 32\n",
    "optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "input_shape = (sample_rate_per_two_seconds, 1)\n",
    "input_tensor = Input(shape = input_shape)\n",
    "metrics = [auc, \"accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Conv1D(16, 9, activation = \"relu\", padding = \"same\")(input_tensor)\n",
    "x = layers.Conv1D(16, 9, activation = \"relu\", padding = \"same\")(x)\n",
    "x = layers.MaxPool1D(16)(x)\n",
    "x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "x = layers.MaxPool1D(4)(x)\n",
    "x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "x = layers.MaxPool1D(4)(x)\n",
    "x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "x = layers.Conv1D(256, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "x = layers.Conv1D(256, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dropout(rate = (drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "x = layers.Dense(64, activation = \"relu\")(x)\n",
    "x = layers.Dense(1028, activation = \"relu\")(x)\n",
    "output_tensor = layers.Dense(number_of_classes, activation = \"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(input_tensor, output_tensor)\n",
    "model.compile(optimizer = optimizer, loss = keras.losses.binary_crossentropy, metrics = metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring model properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = base_dir + \"gunshot_sound_model.pkl\"\n",
    "\n",
    "model_callbacks = [\n",
    "    EarlyStopping(monitor = 'val_acc',\n",
    "                  patience = 10,\n",
    "                  verbose = 1,\n",
    "                  mode = 'auto'),\n",
    "    \n",
    "    ModelCheckpoint(model_filename, monitor = 'val_acc',\n",
    "                    verbose = 1,\n",
    "                    save_best_only = True,\n",
    "                    mode = 'auto'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging of the model's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & caching the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "History = model.fit(train_wav, train_label, \n",
    "          validation_data = [test_wav, test_label],\n",
    "          epochs = number_of_epochs,\n",
    "          callbacks = model_callbacks,\n",
    "          verbose = 1,\n",
    "          batch_size = batch_size,\n",
    "          shuffle = True)\n",
    "\n",
    "model.save(base_dir + \"gunshot_sound_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing history for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(History.history['acc'])\n",
    "plt.plot(History.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing history for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(History.history['loss'])\n",
    "plt.plot(History.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging of incorrectly-labeled examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(test_wav)\n",
    "y_predicted_classes_test = y_test_pred.argmax(axis = -1)\n",
    "y_actual_classes_test = test_label.argmax(axis = -1)\n",
    "wrong_examples = np.nonzero(y_predicted_classes_test != y_actual_classes_test)\n",
    "print(wrong_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging of an individual incorrectly-labeled example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "sample = np.reshape(test_wav[i], sample_rate_per_two_seconds, )\n",
    "sample_rate = 22050\n",
    "print(y_actual_classes_test[i], y_predicted_classes_test[i])\n",
    "ipd.Audio(sample, rate = sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting labels to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_binarizer.inverse_transform(labels[:, 0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gunshot_detection",
   "language": "python",
   "name": "gunshot_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
