{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Directory Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile\n",
    "import re\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Input, layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of Imported Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.init_notebook_mode(connected=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=[]\n",
    "labels = []\n",
    "sampling_rate_per_two_seconds = 44100\n",
    "input_shape = (sampling_rate_per_two_seconds, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring gunshot sound data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gunshot_sound_dir = \"/home/alexm/Datasets/gunshot_data/gunshot/\"\n",
    "print(\"...Parsing gunshot sounds...\")\n",
    "\n",
    "for file in os.listdir(gunshot_sound_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        try:\n",
    "            #### Adding 2 second-long samples to the list of samples\n",
    "            sample, sample_rate = librosa.load(gunshot_sound_dir + file)\n",
    "            \n",
    "            if len(sample) <= sampling_rate_per_two_seconds:\n",
    "                label = 1\n",
    "                number_of_missing_hertz = sampling_rate_per_two_seconds - len(sample)\n",
    "                padded_sample = np.array(sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "                if np.max(abs(sample)) < 0.25:\n",
    "                    label = 0\n",
    "                    \n",
    "                samples.append(padded_sample)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                for i in range(0, sample.size - sampling_rate_per_two_seconds, sampling_rate_per_two_seconds):\n",
    "                    sample_slice = sample[i : i + sampling_rate_per_two_seconds]\n",
    "                    label = 1\n",
    "                    if np.max(abs(sample_slice)) < 0.25:\n",
    "                        label = 0\n",
    "                        \n",
    "                    samples.append(sample_slice)\n",
    "                    labels.append(label)\n",
    "        except:\n",
    "            sample, sample_rate = soundfile.read(gunshot_sound_dir + file)\n",
    "            print(\"Gunshot sound unrecognized by Librosa:\", sample)\n",
    "            pass\n",
    "\n",
    "print(\"The number of samples of available for training is currently \" + str(len(samples)) + '.')\n",
    "print(\"The number of labels of available for training is currently \" + str(len(labels)) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring sound data from examples of glass breaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glassbreak_sound_dir = \"/home/alexm/Datasets/gunshot_data/glassbreak/\"\n",
    "print(\"...Parsing sounds of glass breaking...\")\n",
    "\n",
    "for file in os.listdir(glassbreak_sound_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        try:\n",
    "            #### Adding 2 second-long samples to the list of samples\n",
    "            sample, sample_rate = librosa.load(glassbreak_sound_dir + file)\n",
    "            \n",
    "            if len(sample) <= sampling_rate_per_two_seconds:\n",
    "                label = 0\n",
    "                number_of_missing_hertz = sampling_rate_per_two_seconds - len(sample)\n",
    "                padded_sample = np.array(sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "\n",
    "                samples.append(padded_sample)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                for i in range(0, sample.size - sampling_rate_per_two_seconds, sampling_rate_per_two_seconds):\n",
    "                    sample_slice = sample[i : i + sampling_rate_per_two_seconds]\n",
    "                    label = 0\n",
    "\n",
    "                    samples.append(sample_slice)\n",
    "                    labels.append(label)\n",
    "        except:\n",
    "            sample, sample_rate = soundfile.read(glassbreak_sound_dir + file)\n",
    "            print(\"Glassbreak sound unrecognized by Librosa:\", sample)\n",
    "            pass\n",
    "\n",
    "print(\"The number of samples of available for training is currently \" + str(len(samples)) + '.')\n",
    "print(\"The number of labels of available for training is currently \" + str(len(labels)) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the CSV file of descriptors for all other kinds of urban sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_types = pd.read_csv(\"/home/alexm/Datasets/urban_sound_labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in all of the urban sound data WAV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_sound_dir = \"/home/alexm/Datasets/urban_sounds/\"\n",
    "print(\"...Parsing urban sounds...\")\n",
    "urban_sound_iterator = 0\n",
    "\n",
    "for file in sorted(os.listdir(urban_sound_dir)):\n",
    "    if file.endswith(\".wav\"):\n",
    "        try:\n",
    "            # Adding 2 second-long samples to the list of samples\n",
    "            urban_sound_iterator = int(re.search(r'\\d+', file).group())\n",
    "            sample, sample_rate = librosa.load(urban_sound_dir + file)\n",
    "            prescribed_label = sound_types.loc[sound_types[\"ID\"] == urban_sound_iterator, \"Class\"].values[0]\n",
    "            \n",
    "            if len(sample) <= sampling_rate_per_two_seconds:\n",
    "                label = 1\n",
    "                number_of_missing_hertz = sampling_rate_per_two_seconds - len(sample)\n",
    "                padded_sample = np.array(sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "                if prescribed_label != \"gun_shot\":\n",
    "                    label = 0\n",
    "                elif np.max(abs(sample)) < 0.25:\n",
    "                    label = 0\n",
    "\n",
    "                samples.append(padded_sample)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                for i in range(0, sample.size - sampling_rate_per_two_seconds, sampling_rate_per_two_seconds):\n",
    "                    sample_slice = sample[i : i + sampling_rate_per_two_seconds]\n",
    "                    if prescribed_label != \"gun_shot\":\n",
    "                        label = 0\n",
    "                    elif np.max(abs(sample_slice)) < 0.25:\n",
    "                        label = 0\n",
    "\n",
    "                    samples.append(sample_slice)\n",
    "                    labels.append(label)\n",
    "\n",
    "        except:\n",
    "            sample, sample_rate = soundfile.read(urban_sound_dir + file)\n",
    "            print(\"Urban sound not recognized by Librosa:\", file)\n",
    "            pass\n",
    "\n",
    "print(\"The number of samples of available for training is currently \" + str(len(samples)) + '.')\n",
    "print(\"The number of labels of available for training is currently \" + str(len(labels)) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving samples and labels as numpy array files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/home/alexm/Datasets/gunshot_sound_samples.npy\", samples)\n",
    "np.save(\"/home/alexm/Datasets/gunshot_sound_labels.npy\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading sample file and label file as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load(\"/home/alexm/Datasets/gunshot_sound_samples.npy\")\n",
    "labels = np.load(\"/home/alexm/Datasets/gunshot_sound_labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging after processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0  # You can change the value of 'i' to adjust which sample is being inspected.\n",
    "sample=samples[i]\n",
    "sample_rate=22050\n",
    "print(\"The number of samples available to the model for training is \" + str(len(samples)) + '.')\n",
    "print(\"The maximum frequency value in sample slice #\" + str(i) + \" is \" + str(np.max(abs(sample))) + '.')\n",
    "print(\"The label associated with sample slice #\" + str(i) + \" is \" + str(labels[i]) + '.')\n",
    "ipd.Audio(sample, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arranging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "samples = np.array(samples)\n",
    "labels = np.array(labels)\n",
    "for train_index, test_index in kf.split(samples):\n",
    "    train_wav, test_wav = samples[train_index], samples[test_index]\n",
    "    train_label, test_label = labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping/restructuring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wav = train_wav.reshape(-1, sampling_rate_per_two_seconds, 1)\n",
    "test_wav = test_wav.reshape(-1, sampling_rate_per_two_seconds, 1)\n",
    "train_label = keras.utils.to_categorical(train_label, 2)\n",
    "test_label = keras.utils.to_categorical(test_label, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging of the training data's shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_wav.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"/home/alexm/Datasets/gunshot_sound_full_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "drop_out_rate = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=input_shape)\n",
    "\n",
    "x = layers.Conv1D(8, 11, padding='valid', activation='relu', strides=1)(input_tensor)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Conv1D(16, 7, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(4)(x)\n",
    "x = layers.Conv1D(32, 5, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(4)(x)\n",
    "x = layers.Conv1D(64, 5, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(6)(x)\n",
    "x = layers.Conv1D(128, 3, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(6)(x)\n",
    "x = layers.Conv1D(256, 3, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(6)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(100, activation='relu')(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.Dense(50, activation='relu')(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.Dense(20, activation='relu')(x)\n",
    "\n",
    "output_tensor = layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "             optimizer=keras.optimizers.Adam(lr = learning_rate),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring model properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = '/home/alexm/Datasets/gunshot_sound_model.pkl'\n",
    "\n",
    "model_callbacks = [\n",
    "    EarlyStopping(monitor='val_acc',\n",
    "                  patience=10,\n",
    "                  verbose=1,\n",
    "                  mode='auto'),\n",
    "    \n",
    "    ModelCheckpoint(model_filename, monitor='val_acc',\n",
    "                    verbose=1,\n",
    "                    save_best_only=True,\n",
    "                    mode='auto'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging of the model's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & caching the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "History = model.fit(train_wav, train_label, \n",
    "          validation_data=[test_wav, test_label],\n",
    "          epochs=50,\n",
    "          callbacks=model_callbacks,\n",
    "          verbose=1,\n",
    "          batch_size=batch_size,\n",
    "          shuffle=True)\n",
    "\n",
    "model.save(\"/home/alexm/Datasets/gunshot_sound_full_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing history for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(History.history['acc'])\n",
    "plt.plot(History.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing history for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(History.history['loss'])\n",
    "plt.plot(History.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging of incorrectly-labeled examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(test_wav)\n",
    "y_predicted_classes_test = y_test_pred.argmax(axis=-1)\n",
    "y_actual_classes_test= test_label.argmax(axis=-1)\n",
    "wrong_examples = np.nonzero(y_predicted_classes_test != y_actual_classes_test)\n",
    "print(wrong_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging of an individual incorrectly-labeled example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 323\n",
    "sample = np.reshape(test_wav[i], sampling_rate_per_two_seconds, )\n",
    "sample_rate = 22050\n",
    "print(y_actual_classes_test[i], y_predicted_classes_test[i])\n",
    "ipd.Audio(sample, rate=sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
