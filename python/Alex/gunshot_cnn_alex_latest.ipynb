{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Directory Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile\n",
    "import re\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Input, layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "py.init_notebook_mode(connected=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=[]\n",
    "labels = []\n",
    "sampling_rate_per_two_seconds = 44100\n",
    "input_shape = (sampling_rate_per_two_seconds, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size = 40, dim = input_shape, n_channels = 3,\n",
    "                 n_classes = 10, shuffle = True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        ### Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        ### Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        \n",
    "        ### Generate data\n",
    "        X = self.__data_generation(list_IDs_temp)\n",
    "        \n",
    "        y = self.labels[indexes]\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        ### Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            image = cv2.imread('path to spectrograms' + ID)\n",
    "            # gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            # X[i,] = gray.reshape((224,230,1))\n",
    "            X[i,] = image\n",
    "            X[i,] /= 255\n",
    "            \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring gunshot sound data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Parsing gunshot sounds...\n",
      "The number of samples of available for training is currently 874.\n",
      "The number of labels of available for training is currently 874.\n"
     ]
    }
   ],
   "source": [
    "gunshot_sound_dir = \"/home/alexm/Datasets/gunshot_data/gunshot/\"\n",
    "print(\"...Parsing gunshot sounds...\")\n",
    "\n",
    "for file in os.listdir(gunshot_sound_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        try:\n",
    "            #### Adding 2 second-long samples to the list of samples\n",
    "            sample, sample_rate = librosa.load(gunshot_sound_dir + file)\n",
    "            \n",
    "            if len(sample) <= sampling_rate_per_two_seconds:\n",
    "                label = 1\n",
    "                number_of_missing_hertz = sampling_rate_per_two_seconds - len(sample)\n",
    "                padded_sample = np.array(sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "                if np.max(abs(sample)) < 0.25:\n",
    "                    label = 0\n",
    "                    \n",
    "                samples.append(padded_sample)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                for i in range(0, sample.size - sampling_rate_per_two_seconds, sampling_rate_per_two_seconds):\n",
    "                    sample_slice = sample[i : i + sampling_rate_per_two_seconds]\n",
    "                    label = 1\n",
    "                    if np.max(abs(sample_slice)) < 0.25:\n",
    "                        label = 0\n",
    "                        \n",
    "                    samples.append(sample_slice)\n",
    "                    labels.append(label)\n",
    "        except:\n",
    "            sample, sample_rate = soundfile.read(gunshot_sound_dir + file)\n",
    "            print(\"Gunshot sound unrecognized by Librosa:\", sample)\n",
    "            pass\n",
    "\n",
    "print(\"The number of samples of available for training is currently \" + str(len(samples)) + '.')\n",
    "print(\"The number of labels of available for training is currently \" + str(len(labels)) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring sound data from examples of glass breaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Parsing sounds of glass breaking...\n",
      "The number of samples of available for training is currently 1222.\n",
      "The number of labels of available for training is currently 1222.\n"
     ]
    }
   ],
   "source": [
    "glassbreak_sound_dir = \"/home/alexm/Datasets/gunshot_data/glassbreak/\"\n",
    "print(\"...Parsing sounds of glass breaking...\")\n",
    "\n",
    "for file in os.listdir(glassbreak_sound_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        try:\n",
    "            #### Adding 2 second-long samples to the list of samples\n",
    "            sample, sample_rate = librosa.load(glassbreak_sound_dir + file)\n",
    "            \n",
    "            if len(sample) <= sampling_rate_per_two_seconds:\n",
    "                label = 1\n",
    "                number_of_missing_hertz = sampling_rate_per_two_seconds - len(sample)\n",
    "                padded_sample = np.array(sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "                if np.max(abs(sample)) < 0.25:\n",
    "                    label = 0\n",
    "\n",
    "                samples.append(padded_sample)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                for i in range(0, sample.size - sampling_rate_per_two_seconds, sampling_rate_per_two_seconds):\n",
    "                    sample_slice = sample[i : i + sampling_rate_per_two_seconds]\n",
    "                    label = 1\n",
    "                    if np.max(abs(sample_slice)) < 0.25:\n",
    "                        label = 0\n",
    "\n",
    "                    samples.append(sample_slice)\n",
    "                    labels.append(label)\n",
    "        except:\n",
    "            sample, sample_rate = soundfile.read(glassbreak_sound_dir + file)\n",
    "            print(\"Glassbreak sound unrecognized by Librosa:\", sample)\n",
    "            pass\n",
    "\n",
    "print(\"The number of samples of available for training is currently \" + str(len(samples)) + '.')\n",
    "print(\"The number of labels of available for training is currently \" + str(len(labels)) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the CSV file of descriptors for all other kinds of urban sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_types = pd.read_csv(\"/home/alexm/Datasets/urban_sound_labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in all of the urban sound data WAV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Parsing urban sounds...\n",
      "The number of samples of available for training is currently 6658.\n",
      "The number of labels of available for training is currently 6658.\n"
     ]
    }
   ],
   "source": [
    "urban_sound_dir = \"/home/alexm/Datasets/urban_sounds/\"\n",
    "print(\"...Parsing urban sounds...\")\n",
    "urban_sound_iterator = 0\n",
    "\n",
    "for file in sorted(os.listdir(urban_sound_dir)):\n",
    "    if file.endswith(\".wav\"):\n",
    "        try:\n",
    "            # Adding 2 second-long samples to the list of samples\n",
    "            urban_sound_iterator = int(re.search(r'\\d+', file).group())\n",
    "            sample, sample_rate = librosa.load(urban_sound_dir + file)\n",
    "            prescribed_label = sound_types.loc[sound_types[\"ID\"] == urban_sound_iterator, \"Class\"].values[0]\n",
    "            \n",
    "            if len(sample) <= sampling_rate_per_two_seconds:\n",
    "                label = 1\n",
    "                number_of_missing_hertz = sampling_rate_per_two_seconds - len(sample)\n",
    "                padded_sample = np.array(sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "                if prescribed_label != \"gun_shot\":\n",
    "                    label = 0\n",
    "                elif np.max(abs(sample)) < 0.25:\n",
    "                    label = 0\n",
    "\n",
    "                samples.append(padded_sample)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                for i in range(0, sample.size - sampling_rate_per_two_seconds, sampling_rate_per_two_seconds):\n",
    "                    sample_slice = sample[i : i + sampling_rate_per_two_seconds]\n",
    "                    if prescribed_label != \"gun_shot\":\n",
    "                        label = 0\n",
    "                    elif np.max(abs(sample_slice)) < 0.25:\n",
    "                        label = 0\n",
    "\n",
    "                    samples.append(sample_slice)\n",
    "                    labels.append(label)\n",
    "\n",
    "        except:\n",
    "            sample, sample_rate = soundfile.read(urban_sound_dir + file)\n",
    "            print(\"Urban sound not recognized by Librosa:\", file)\n",
    "            pass\n",
    "\n",
    "print(\"The number of samples of available for training is currently \" + str(len(samples)) + '.')\n",
    "print(\"The number of labels of available for training is currently \" + str(len(labels)) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving samples and labels as numpy array files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/home/alexm/Datasets/gunshot_sound_samples.npy\", samples)\n",
    "np.save(\"/home/alexm/Datasets/gunshot_sound_labels.npy\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading sample file and label file as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load(\"/home/alexm/Datasets/gunshot_sound_samples.npy\")\n",
    "labels = np.load(\"/home/alexm/Datasets/gunshot_sound_labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging after processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0  # You can change the value of 'i' to adjust which sample is being inspected.\n",
    "sample=samples[i]\n",
    "sample_rate=22050\n",
    "print(\"The number of samples available to the model for training is \" + str(len(samples)) + '.')\n",
    "print(\"The maximum frequency value in sample slice #\" + str(i) + \" is \" + str(np.max(abs(sample))) + '.')\n",
    "print(\"The label associated with sample slice #\" + str(i) + \" is \" + str(labels[i]) + '.')\n",
    "ipd.Audio(sample, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arranging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "samples = np.array(samples)\n",
    "labels = np.array(labels)\n",
    "for train_index, test_index in kf.split(samples):\n",
    "    train_wav, test_wav = samples[train_index], samples[test_index]\n",
    "    train_label, test_label = labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping/restructuring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wav = train_wav.reshape(-1, sampling_rate_per_two_seconds, 1)\n",
    "test_wav = test_wav.reshape(-1, sampling_rate_per_two_seconds, 1)\n",
    "train_label = keras.utils.to_categorical(train_label, 2)\n",
    "test_label = keras.utils.to_categorical(test_label, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging of the training data's shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_wav.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "drop_out_rate = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=input_shape)\n",
    "\n",
    "x = layers.Conv1D(8, 11, padding='valid', activation='relu', strides=1)(input_tensor)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Conv1D(16, 7, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(4)(x)\n",
    "x = layers.Conv1D(32, 5, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(4)(x)\n",
    "x = layers.Conv1D(64, 5, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(6)(x)\n",
    "x = layers.Conv1D(128, 3, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(6)(x)\n",
    "x = layers.Conv1D(256, 3, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(6)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(100, activation='relu')(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.Dense(50, activation='relu')(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.Dense(20, activation='relu')(x)\n",
    "\n",
    "output_tensor = layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "             optimizer=keras.optimizers.Adam(lr = learning_rate),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring model properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'gunshot_sound_model.pkl'\n",
    "\n",
    "model_callbacks = [\n",
    "    EarlyStopping(monitor='val_acc',\n",
    "                  patience=10,\n",
    "                  verbose=1,\n",
    "                  mode='auto'),\n",
    "    \n",
    "    ModelCheckpoint(model_filename, monitor='val_acc',\n",
    "                    verbose=1,\n",
    "                    save_best_only=True,\n",
    "                    mode='auto'),\n",
    "]\n",
    "\n",
    "training_generator = DataGenerator(train_wav, train_label)\n",
    "validation_generator = DataGenerator(test_wav, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging of the model's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & caching the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_wav, train_label, \n",
    "          validation_data=[test_wav, test_label],\n",
    "          batch_size=batch_size, \n",
    "          epochs=50,\n",
    "          callbacks=model_callbacks,\n",
    "          verbose=1)\n",
    "\n",
    "# model.load_weights(\"gunshot_sound_model.h5\")\n",
    "y_pred = np.round(model.predict(X_test))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "model.save_weights(\"gunshot_sound_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing history for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(History.history['acc'])\n",
    "plt.plot(History.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing history for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(History.history['loss'])\n",
    "plt.plot(History.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging of incorrectly-labeled examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = model.predict(test_wav)\n",
    "y_predicted_classes_test = Y_test_pred.argmax(axis=-1)\n",
    "y_actual_classes_test= test_label.argmax(axis=-1)\n",
    "wrong_examples = np.nonzero(y_predicted_classes_test != y_actual_classes_test)\n",
    "print(wrong_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging of an individual incorrectly-labeled example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "sample = np.reshape(test_wav[i], sampling_rate_per_two_seconds, )\n",
    "sample_rate = 22050\n",
    "print(y_test[i], Y_test_pred[i])\n",
    "ipd.Audio(sample, rate=sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
